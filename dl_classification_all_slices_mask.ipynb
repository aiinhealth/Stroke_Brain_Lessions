{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # this MUST come before any tf call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed for reproductibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 1337\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23683,
     "status": "ok",
     "timestamp": 1611332119076,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "bnVqG921PacZ",
    "outputId": "e453e7b4-8b93-46f8-eebd-2014073dd3ff"
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "import os\n",
    "import shutil\n",
    "import SimpleITK as sitk\n",
    "import scipy.spatial\n",
    "from glob import glob\n",
    "from typing import  List\n",
    "from pprint import pprint  \n",
    "import json\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "import SimpleITK as sitk\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Cropping2D, ZeroPadding2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.activations import elu\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "base_path = '/your/root/path'\n",
    "datasets_path = f'{base_path}/datasets/paper lesions extended'\n",
    "models_path = f'{base_path}/modelos/paper lesions extended'\n",
    "mni_T1_path = TEMPLATE_PATH = f'{base_path}/datasets/templates/mni_icbm152_t1_tal_nlin_sym_09a.nii'\n",
    "clf_dataset = f'{datasets_path}/STANDARD_BY_CLASSIFICATION'\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20007,
     "status": "ok",
     "timestamp": 1611332125893,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "HcRJJ6-qTndO",
    "outputId": "aee1c406-e6ee-40fe-daa9-4e7f0cee6ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['/home/carlos.jimenez/ai-in-health/Stroke-Brain-Lesions/datasets/paper lesions extended/STANDARD_BY_CLASSIFICATION/test/Lacunar', '/home/carlos.jimenez/ai-in-health/Stroke-Brain-Lesions/datasets/paper lesions extended/STANDARD_BY_CLASSIFICATION/test/MCA', '/home/carlos.jimenez/ai-in-health/Stroke-Brain-Lesions/datasets/paper lesions extended/STANDARD_BY_CLASSIFICATION/train/Lacunar', '/home/carlos.jimenez/ai-in-health/Stroke-Brain-Lesions/datasets/paper lesions extended/STANDARD_BY_CLASSIFICATION/train/MCA']\n"
     ]
    }
   ],
   "source": [
    "folders =  sorted(glob(f'{clf_dataset}/*/*'))\n",
    "print(len(folders))\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc0bdbQ3l171"
   },
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1616644812025,
     "user": {
      "displayName": "Roberto Alejandro Mena Ramirez",
      "photoUrl": "",
      "userId": "17762559014980159599"
     },
     "user_tz": 300
    },
    "id": "DZ_PYWpnzKIa"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "IMG_SIZE = 128 # 224\n",
    "BATCH_SIZE = 1024 # 64\n",
    "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "LR = 1e-04\n",
    "WD = 4e-03\n",
    "TRAIN_PATH = f'{clf_dataset}/train'\n",
    "TEST_PATH = f'{clf_dataset}/test'\n",
    "class_mode = 'categorical'\n",
    "loss = f'{class_mode}_crossentropy'\n",
    "dense_layers = 3\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(\n",
    "#     learning_rate=tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate=LR, first_decay_steps=300), \n",
    "#     decay=WD\n",
    "# )\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LR, decay=WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    \"\"\"\n",
    "    Learning rate scheduler function.\n",
    "\n",
    "    Args:\n",
    "        epoch (int): The current epoch number.\n",
    "        lr (float): The current learning rate.\n",
    "\n",
    "    Returns:\n",
    "        float: The updated learning rate.\n",
    "\n",
    "    \"\"\"\n",
    "    if epoch % 10 == 0:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "8cBrcD42wLbG"
   },
   "outputs": [],
   "source": [
    "def create_datagenerators(dataset, preprocessing_function, val_split=0.2, image_size=IMG_SIZE, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Creates data generators for training and validation.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): The path to the dataset directory.\n",
    "        preprocessing_function (function): The preprocessing function to apply to the images.\n",
    "        val_split (float): The fraction of data to use for validation.\n",
    "        image_size (int): The target image size for resizing.\n",
    "        batch_size (int): The batch size for the data generators.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training and validation data generators.\n",
    "\n",
    "    \"\"\"\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "        validation_split=val_split,\n",
    "#         fill_mode=\"constant\",\n",
    "        preprocessing_function=preprocessing_function\n",
    "    )\n",
    "\n",
    "    # Create a generator for our training data\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        dataset,\n",
    "        class_mode=class_mode,\n",
    "        shuffle=True,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        seed=seed,\n",
    "        subset=\"training\"\n",
    "    )\n",
    "\n",
    "    # Create a generator for our validation data\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        dataset,\n",
    "        class_mode=class_mode,\n",
    "        shuffle=True,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        seed=seed,\n",
    "        subset=\"validation\"\n",
    "    )\n",
    "  \n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vWAkz0xdS6z"
   },
   "source": [
    "## Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqtCNWeTc6b4"
   },
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cxmI7gK4XloK"
   },
   "outputs": [],
   "source": [
    "# Create a function which builds a Keras model\n",
    "def create_model_vgg19(input_shape=INPUT_SHAPE):\n",
    "    \"\"\"\n",
    "    Create a Keras model based on VGG19 architecture.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The input shape of the model. Default is INPUT_SHAPE.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The created Keras model.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Building model...\")\n",
    "    # Setup the model layers\n",
    "    base_model_VGG19 = tf.keras.applications.VGG19(include_top=False, \n",
    "                                                 weights='imagenet', \n",
    "                                                 input_shape=INPUT_SHAPE,\n",
    "                                                 classifier_activation='relu')\n",
    "\n",
    "    #  base vgg19 layers = 22\n",
    "    base_model_VGG19.trainable = False    # IMPORTANT - Freeze the convolutional base \n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "       base_model_VGG19,\n",
    "       tf.keras.layers.Flatten()\n",
    "    ])\n",
    "    \n",
    "    for i in range(dense_layers):\n",
    "        model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.6))\n",
    "    \n",
    "    if class_mode == 'categorical':\n",
    "        model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "    elif class_mode == 'binary':\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "      loss=loss,\n",
    "      optimizer=optimizer,\n",
    "      metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2aWXGQ6-AFF"
   },
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "lM7GX6Ua9-x3"
   },
   "outputs": [],
   "source": [
    "def create_model_inceptionv3(input_shape=INPUT_SHAPE):\n",
    "    \"\"\"\n",
    "    Create a Keras model based on InceptionV3 architecture.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The input shape of the model. Default is INPUT_SHAPE.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The created Keras model.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Building model...\")\n",
    "    # Setup the model layers\n",
    "    base_model_InceptionV3 = tf.keras.applications.InceptionV3(include_top=False, \n",
    "                                                 weights='imagenet', \n",
    "                                                 input_shape=INPUT_SHAPE,\n",
    "                                                 classifier_activation='relu')\n",
    "    \n",
    "    #  base inceptionv3 layers = 311\n",
    "    base_model_InceptionV3.trainable = False # IMPORTANT - Freeze the convolutional base\n",
    "\n",
    "    for layer in  base_model_InceptionV3.layers[133:]:\n",
    "#         print(layer.name)\n",
    "        layer.trainable=True\n",
    "\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "       base_model_InceptionV3,\n",
    "       tf.keras.layers.Flatten()\n",
    "    ])\n",
    "    \n",
    "    for i in range(dense_layers):\n",
    "        model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.6))\n",
    "    \n",
    "    if class_mode == 'categorical':\n",
    "        model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "    elif class_mode == 'binary':\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "      loss=loss,\n",
    "      optimizer=optimizer,\n",
    "      metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ecp4ZlGJef2"
   },
   "source": [
    "### ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "NHb2uYD0JkSO"
   },
   "outputs": [],
   "source": [
    "def create_model_resnet50v2(input_shape=INPUT_SHAPE):\n",
    "    \"\"\"\n",
    "    Create a Keras model based on ResNet50V2 architecture.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The input shape of the model. Default is INPUT_SHAPE.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The created Keras model.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Building model...\")\n",
    "\n",
    "    # Setup the model layers\n",
    "    base_model_ResNet50V2 = tf.keras.applications.ResNet50V2(include_top=False, \n",
    "                                                 weights='imagenet', \n",
    "                                                 input_shape=INPUT_SHAPE,\n",
    "                                                 classifier_activation='relu')\n",
    "    #  base resnet50v2 layers = 190\n",
    "    base_model_ResNet50V2.trainable = False # IMPORTANT - Freeze the convolutional base\n",
    "\n",
    "    for layer in  base_model_ResNet50V2.layers[120:]:\n",
    "#         print(layer.name)\n",
    "        layer.trainable=True\n",
    "#         print(layer.name)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "       base_model_ResNet50V2,\n",
    "       tf.keras.layers.Flatten()\n",
    "    ])\n",
    "    \n",
    "    for i in range(dense_layers):\n",
    "        model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.6))\n",
    "    \n",
    "    if class_mode == 'categorical':\n",
    "        model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "    elif class_mode == 'binary':\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "      loss=loss,\n",
    "      optimizer=optimizer,\n",
    "      metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGx5_OYPKP0V"
   },
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "6215JEBqKV3O"
   },
   "outputs": [],
   "source": [
    "def create_model_mobilenetv2(input_shape=INPUT_SHAPE):\n",
    "    \"\"\"\n",
    "    Create a Keras model based on MobileNetV2 architecture.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The input shape of the model. Default is INPUT_SHAPE.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The created Keras model.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Building model...\")\n",
    "    # Setup the model layers\n",
    "    base_model_MobileNetV2 = tf.keras.applications.MobileNetV2(include_top=False, \n",
    "                                                 weights='imagenet', \n",
    "                                                 input_shape=INPUT_SHAPE,\n",
    "                                                 classifier_activation='relu')\n",
    "    #  base mobilenetv2 layers = 154\n",
    "    base_model_MobileNetV2.trainable = False # IMPORTANT - Freeze the convolutional base\n",
    "    \n",
    "    for layer in base_model_MobileNetV2.layers[90:]:\n",
    "#         print(layer.name)\n",
    "        layer.trainable=True\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "                               base_model_MobileNetV2,\n",
    "                               tf.keras.layers.Flatten(),\n",
    "    ])\n",
    "    \n",
    "    for i in range(dense_layers):\n",
    "        model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.6))\n",
    "\n",
    "    if class_mode == 'categorical':\n",
    "        model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "    elif class_mode == 'binary':\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "      loss=loss,\n",
    "      optimizer=optimizer,\n",
    "      metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i80fLfEMRMc"
   },
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2311,
     "status": "ok",
     "timestamp": 1611332168849,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "GYtTTze0fKMm",
    "outputId": "4f3b73b5-37ee-468f-e0c5-e8f0f1b23546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model_vgg19 = create_model_vgg19()\n",
    "# model_vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3928,
     "status": "ok",
     "timestamp": 1610018896816,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "PSuYUOuSMdYX",
    "outputId": "e1adfb14-d690-4bfe-bfe0-78f871f8598c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model_inceptionv3 = create_model_inceptionv3()\n",
    "# model_inceptionv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3883,
     "status": "ok",
     "timestamp": 1610027630260,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "CbkxCykCNFXY",
    "outputId": "b0dc7179-e52d-41ff-d49b-4707fb8d6cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model_resnet50v2 = create_model_resnet50v2()\n",
    "# model_resnet50v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2199,
     "status": "ok",
     "timestamp": 1610041964629,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "l3glCGsSNg1e",
    "outputId": "c76e7590-a3b1-4bac-d119-a50d40b6c796"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model_mobilenetv2 = create_model_mobilenetv2()\n",
    "# model_mobilenetv2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbdswnaaPHj0"
   },
   "source": [
    "## Validation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74X7-_ofiRW_"
   },
   "source": [
    "### Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "_UdwSKnukRZD"
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = f\"{models_path}/classification/inceptionV3_{NUM_EPOCHS}epocas_{len(model_inceptionv3.layers)}capas_lr_{str(LR)}.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(model, metrics):\n",
    "    \"\"\"\n",
    "    Log and save the evaluation metrics of a model to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        model (str): The name or identifier of the model.\n",
    "        metrics (dict): A dictionary containing the evaluation metrics to be logged.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    save_path = f'{datasets_path}/results/{model}/metrics_{datetime.now().strftime(\"%Y%m%d%H%M-%S\")}.json'\n",
    "    with open(save_path, 'w') as fp:\n",
    "        json.dump(str(metrics), fp)\n",
    "        \n",
    "    print(f'json saved to {save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQkprIObSgHD"
   },
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1611332189990,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "L6l3nxdXhK8H",
    "outputId": "bfaabe82-206b-4bfe-8b90-9f32a238bad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6618 images belonging to 2 classes.\n",
      "Found 1653 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = create_datagenerators(\n",
    "    TRAIN_PATH, \n",
    "    preprocessing_function=keras.applications.inception_v3.preprocess_input\n",
    ")\n",
    "\n",
    "training_steps = train_generator.n//train_generator.batch_size\n",
    "validation_steps = val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UDBHfCUWy3S"
   },
   "source": [
    "# InceptionV3\n",
    "The network is trained using the InceptionV3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2107824,
     "status": "ok",
     "timestamp": 1610049452561,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "XBFlyFCbL2ro",
    "outputId": "b7622aa7-895f-4969-c980-cd519817de66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "6/6 [==============================] - 57s 2s/step - loss: 0.9655 - accuracy: 0.5195 - val_loss: 0.6643 - val_accuracy: 0.6064 - lr: 9.0484e-05\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 5s 952ms/step - loss: 0.7986 - accuracy: 0.5299 - val_loss: 0.6665 - val_accuracy: 0.6172 - lr: 9.0484e-05\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 5s 938ms/step - loss: 0.7343 - accuracy: 0.5458 - val_loss: 0.6588 - val_accuracy: 0.6748 - lr: 9.0484e-05\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 5s 939ms/step - loss: 0.7077 - accuracy: 0.5506 - val_loss: 0.6422 - val_accuracy: 0.7002 - lr: 9.0484e-05\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 5s 934ms/step - loss: 0.6743 - accuracy: 0.5788 - val_loss: 0.6314 - val_accuracy: 0.7158 - lr: 9.0484e-05\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 5s 950ms/step - loss: 0.6639 - accuracy: 0.5915 - val_loss: 0.6045 - val_accuracy: 0.7412 - lr: 9.0484e-05\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 5s 859ms/step - loss: 0.6541 - accuracy: 0.6017 - val_loss: 0.5972 - val_accuracy: 0.7197 - lr: 9.0484e-05\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 5s 791ms/step - loss: 0.6401 - accuracy: 0.6176 - val_loss: 0.5816 - val_accuracy: 0.7305 - lr: 9.0484e-05\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 5s 789ms/step - loss: 0.6308 - accuracy: 0.6267 - val_loss: 0.5639 - val_accuracy: 0.7285 - lr: 9.0484e-05\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 5s 943ms/step - loss: 0.6245 - accuracy: 0.6284 - val_loss: 0.5540 - val_accuracy: 0.7461 - lr: 9.0484e-05\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 5s 945ms/step - loss: 0.6194 - accuracy: 0.6400 - val_loss: 0.5373 - val_accuracy: 0.7578 - lr: 8.1873e-05\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 5s 929ms/step - loss: 0.6068 - accuracy: 0.6466 - val_loss: 0.5211 - val_accuracy: 0.7734 - lr: 8.1873e-05\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 5s 951ms/step - loss: 0.6043 - accuracy: 0.6494 - val_loss: 0.5162 - val_accuracy: 0.7793 - lr: 8.1873e-05\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 5s 821ms/step - loss: 0.5949 - accuracy: 0.6616 - val_loss: 0.5205 - val_accuracy: 0.7412 - lr: 8.1873e-05\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 5s 807ms/step - loss: 0.5881 - accuracy: 0.6695 - val_loss: 0.4942 - val_accuracy: 0.7529 - lr: 8.1873e-05\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 5s 786ms/step - loss: 0.5845 - accuracy: 0.6673 - val_loss: 0.4939 - val_accuracy: 0.7568 - lr: 8.1873e-05\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 5s 846ms/step - loss: 0.5816 - accuracy: 0.6750 - val_loss: 0.4784 - val_accuracy: 0.7764 - lr: 8.1873e-05\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 5s 796ms/step - loss: 0.5700 - accuracy: 0.6845 - val_loss: 0.4760 - val_accuracy: 0.7764 - lr: 8.1873e-05\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.5578 - accuracy: 0.7010 - val_loss: 0.4672 - val_accuracy: 0.7910 - lr: 8.1873e-05\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.5582 - accuracy: 0.6986 - val_loss: 0.4541 - val_accuracy: 0.7988 - lr: 8.1873e-05\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 5s 829ms/step - loss: 0.5562 - accuracy: 0.6979 - val_loss: 0.4567 - val_accuracy: 0.7920 - lr: 7.4082e-05\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 5s 792ms/step - loss: 0.5532 - accuracy: 0.7013 - val_loss: 0.4583 - val_accuracy: 0.7764 - lr: 7.4082e-05\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 5s 943ms/step - loss: 0.5501 - accuracy: 0.7025 - val_loss: 0.4490 - val_accuracy: 0.8008 - lr: 7.4082e-05\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 5s 797ms/step - loss: 0.5455 - accuracy: 0.7083 - val_loss: 0.4550 - val_accuracy: 0.7803 - lr: 7.4082e-05\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 5s 806ms/step - loss: 0.5362 - accuracy: 0.7151 - val_loss: 0.4516 - val_accuracy: 0.7793 - lr: 7.4082e-05\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 5s 816ms/step - loss: 0.5250 - accuracy: 0.7285 - val_loss: 0.4372 - val_accuracy: 0.7979 - lr: 7.4082e-05\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 5s 793ms/step - loss: 0.5333 - accuracy: 0.7249 - val_loss: 0.4427 - val_accuracy: 0.7949 - lr: 7.4082e-05\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 5s 794ms/step - loss: 0.5315 - accuracy: 0.7310 - val_loss: 0.4449 - val_accuracy: 0.7783 - lr: 7.4082e-05\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 5s 786ms/step - loss: 0.5283 - accuracy: 0.7238 - val_loss: 0.4450 - val_accuracy: 0.7832 - lr: 7.4082e-05\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.5178 - accuracy: 0.7344 - val_loss: 0.4199 - val_accuracy: 0.8203 - lr: 7.4082e-05\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 5s 804ms/step - loss: 0.5248 - accuracy: 0.7249 - val_loss: 0.4129 - val_accuracy: 0.8154 - lr: 6.7032e-05\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 5s 790ms/step - loss: 0.5151 - accuracy: 0.7340 - val_loss: 0.4279 - val_accuracy: 0.7959 - lr: 6.7032e-05\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 5s 810ms/step - loss: 0.5107 - accuracy: 0.7315 - val_loss: 0.4306 - val_accuracy: 0.7861 - lr: 6.7032e-05\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 5s 841ms/step - loss: 0.5093 - accuracy: 0.7379 - val_loss: 0.4324 - val_accuracy: 0.7910 - lr: 6.7032e-05\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 5s 809ms/step - loss: 0.5079 - accuracy: 0.7437 - val_loss: 0.4373 - val_accuracy: 0.7803 - lr: 6.7032e-05\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 5s 794ms/step - loss: 0.5033 - accuracy: 0.7471 - val_loss: 0.4357 - val_accuracy: 0.7861 - lr: 6.7032e-05\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 5s 877ms/step - loss: 0.5041 - accuracy: 0.7413 - val_loss: 0.4241 - val_accuracy: 0.8018 - lr: 6.7032e-05\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 5s 805ms/step - loss: 0.4999 - accuracy: 0.7492 - val_loss: 0.4161 - val_accuracy: 0.8008 - lr: 6.7032e-05\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 5s 796ms/step - loss: 0.5000 - accuracy: 0.7454 - val_loss: 0.4277 - val_accuracy: 0.8008 - lr: 6.7032e-05\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 5s 952ms/step - loss: 0.4977 - accuracy: 0.7512 - val_loss: 0.4121 - val_accuracy: 0.8223 - lr: 6.7032e-05\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 5s 803ms/step - loss: 0.4938 - accuracy: 0.7408 - val_loss: 0.4197 - val_accuracy: 0.7998 - lr: 6.0653e-05\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 5s 797ms/step - loss: 0.4884 - accuracy: 0.7619 - val_loss: 0.4272 - val_accuracy: 0.8008 - lr: 6.0653e-05\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 5s 785ms/step - loss: 0.4951 - accuracy: 0.7503 - val_loss: 0.4185 - val_accuracy: 0.8027 - lr: 6.0653e-05\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 5s 796ms/step - loss: 0.4853 - accuracy: 0.7622 - val_loss: 0.4202 - val_accuracy: 0.7998 - lr: 6.0653e-05\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 5s 801ms/step - loss: 0.4865 - accuracy: 0.7637 - val_loss: 0.4249 - val_accuracy: 0.8008 - lr: 6.0653e-05\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 5s 805ms/step - loss: 0.4775 - accuracy: 0.7571 - val_loss: 0.4163 - val_accuracy: 0.8047 - lr: 6.0653e-05\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 5s 795ms/step - loss: 0.4859 - accuracy: 0.7656 - val_loss: 0.4202 - val_accuracy: 0.8057 - lr: 6.0653e-05\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 5s 786ms/step - loss: 0.4863 - accuracy: 0.7569 - val_loss: 0.4167 - val_accuracy: 0.8008 - lr: 6.0653e-05\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 5s 827ms/step - loss: 0.4698 - accuracy: 0.7617 - val_loss: 0.4188 - val_accuracy: 0.8096 - lr: 6.0653e-05\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 5s 866ms/step - loss: 0.4780 - accuracy: 0.7599 - val_loss: 0.4296 - val_accuracy: 0.7979 - lr: 6.0653e-05\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 5s 810ms/step - loss: 0.4712 - accuracy: 0.7658 - val_loss: 0.4091 - val_accuracy: 0.8164 - lr: 5.4881e-05\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 5s 868ms/step - loss: 0.4706 - accuracy: 0.7681 - val_loss: 0.4107 - val_accuracy: 0.8145 - lr: 5.4881e-05\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 5s 821ms/step - loss: 0.4738 - accuracy: 0.7644 - val_loss: 0.4188 - val_accuracy: 0.8047 - lr: 5.4881e-05\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 5s 820ms/step - loss: 0.4697 - accuracy: 0.7647 - val_loss: 0.4116 - val_accuracy: 0.8203 - lr: 5.4881e-05\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.4664 - accuracy: 0.7694 - val_loss: 0.4131 - val_accuracy: 0.8154 - lr: 5.4881e-05\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 5s 841ms/step - loss: 0.4684 - accuracy: 0.7703 - val_loss: 0.4150 - val_accuracy: 0.8018 - lr: 5.4881e-05\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 5s 801ms/step - loss: 0.4735 - accuracy: 0.7624 - val_loss: 0.4117 - val_accuracy: 0.8057 - lr: 5.4881e-05\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 5s 820ms/step - loss: 0.4694 - accuracy: 0.7706 - val_loss: 0.4113 - val_accuracy: 0.8096 - lr: 5.4881e-05\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 5s 859ms/step - loss: 0.4586 - accuracy: 0.7739 - val_loss: 0.4126 - val_accuracy: 0.8105 - lr: 5.4881e-05\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 5s 823ms/step - loss: 0.4552 - accuracy: 0.7758 - val_loss: 0.4115 - val_accuracy: 0.8154 - lr: 5.4881e-05\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 5s 812ms/step - loss: 0.4582 - accuracy: 0.7832 - val_loss: 0.3980 - val_accuracy: 0.8145 - lr: 4.9659e-05\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 5s 822ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4065 - val_accuracy: 0.8076 - lr: 4.9659e-05\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 5s 815ms/step - loss: 0.4537 - accuracy: 0.7823 - val_loss: 0.3949 - val_accuracy: 0.8184 - lr: 4.9659e-05\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 5s 812ms/step - loss: 0.4613 - accuracy: 0.7749 - val_loss: 0.4060 - val_accuracy: 0.8105 - lr: 4.9659e-05\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 5s 900ms/step - loss: 0.4575 - accuracy: 0.7751 - val_loss: 0.3868 - val_accuracy: 0.8223 - lr: 4.9659e-05\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 5s 798ms/step - loss: 0.4524 - accuracy: 0.7773 - val_loss: 0.4152 - val_accuracy: 0.8086 - lr: 4.9659e-05\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 5s 870ms/step - loss: 0.4530 - accuracy: 0.7804 - val_loss: 0.3975 - val_accuracy: 0.8193 - lr: 4.9659e-05\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 5s 820ms/step - loss: 0.4474 - accuracy: 0.7835 - val_loss: 0.4055 - val_accuracy: 0.8076 - lr: 4.9659e-05\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 5s 805ms/step - loss: 0.4553 - accuracy: 0.7832 - val_loss: 0.4041 - val_accuracy: 0.8027 - lr: 4.9659e-05\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 5s 928ms/step - loss: 0.4441 - accuracy: 0.7862 - val_loss: 0.4157 - val_accuracy: 0.8096 - lr: 4.9659e-05\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 5s 807ms/step - loss: 0.4444 - accuracy: 0.7880 - val_loss: 0.3960 - val_accuracy: 0.8223 - lr: 4.4933e-05\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 5s 800ms/step - loss: 0.4422 - accuracy: 0.7925 - val_loss: 0.4012 - val_accuracy: 0.8115 - lr: 4.4933e-05\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 5s 814ms/step - loss: 0.4495 - accuracy: 0.7805 - val_loss: 0.4131 - val_accuracy: 0.8076 - lr: 4.4933e-05\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 5s 837ms/step - loss: 0.4474 - accuracy: 0.7876 - val_loss: 0.4079 - val_accuracy: 0.8037 - lr: 4.4933e-05\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 5s 818ms/step - loss: 0.4432 - accuracy: 0.7903 - val_loss: 0.4004 - val_accuracy: 0.8018 - lr: 4.4933e-05\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 5s 811ms/step - loss: 0.4421 - accuracy: 0.7930 - val_loss: 0.4007 - val_accuracy: 0.8047 - lr: 4.4933e-05\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 5s 879ms/step - loss: 0.4405 - accuracy: 0.7878 - val_loss: 0.3982 - val_accuracy: 0.8145 - lr: 4.4933e-05\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 5s 800ms/step - loss: 0.4486 - accuracy: 0.7887 - val_loss: 0.4078 - val_accuracy: 0.8115 - lr: 4.4933e-05\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 5s 799ms/step - loss: 0.4330 - accuracy: 0.7987 - val_loss: 0.4037 - val_accuracy: 0.8096 - lr: 4.4933e-05\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 5s 810ms/step - loss: 0.4416 - accuracy: 0.7892 - val_loss: 0.3955 - val_accuracy: 0.8115 - lr: 4.4933e-05\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 5s 814ms/step - loss: 0.4369 - accuracy: 0.7891 - val_loss: 0.4046 - val_accuracy: 0.8076 - lr: 4.0657e-05\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 5s 815ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.4058 - val_accuracy: 0.8047 - lr: 4.0657e-05\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 5s 867ms/step - loss: 0.4396 - accuracy: 0.7935 - val_loss: 0.3981 - val_accuracy: 0.8145 - lr: 4.0657e-05\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 5s 896ms/step - loss: 0.4276 - accuracy: 0.7975 - val_loss: 0.4036 - val_accuracy: 0.8086 - lr: 4.0657e-05\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.4317 - accuracy: 0.7905 - val_loss: 0.3878 - val_accuracy: 0.8271 - lr: 4.0657e-05\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 5s 790ms/step - loss: 0.4319 - accuracy: 0.7982 - val_loss: 0.3908 - val_accuracy: 0.8232 - lr: 4.0657e-05\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 5s 833ms/step - loss: 0.4296 - accuracy: 0.7943 - val_loss: 0.4001 - val_accuracy: 0.8135 - lr: 4.0657e-05\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 5s 805ms/step - loss: 0.4324 - accuracy: 0.7898 - val_loss: 0.4144 - val_accuracy: 0.8008 - lr: 4.0657e-05\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.4312 - accuracy: 0.7942 - val_loss: 0.4080 - val_accuracy: 0.8076 - lr: 4.0657e-05\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 5s 809ms/step - loss: 0.4375 - accuracy: 0.7832 - val_loss: 0.4048 - val_accuracy: 0.8066 - lr: 4.0657e-05\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 5s 855ms/step - loss: 0.4258 - accuracy: 0.7980 - val_loss: 0.3821 - val_accuracy: 0.8213 - lr: 3.6788e-05\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 5s 837ms/step - loss: 0.4255 - accuracy: 0.8021 - val_loss: 0.3906 - val_accuracy: 0.8193 - lr: 3.6788e-05\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 5s 814ms/step - loss: 0.4256 - accuracy: 0.7957 - val_loss: 0.3901 - val_accuracy: 0.8232 - lr: 3.6788e-05\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 5s 850ms/step - loss: 0.4144 - accuracy: 0.8049 - val_loss: 0.3938 - val_accuracy: 0.8125 - lr: 3.6788e-05\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 5s 874ms/step - loss: 0.4294 - accuracy: 0.7939 - val_loss: 0.4179 - val_accuracy: 0.7861 - lr: 3.6788e-05\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 5s 799ms/step - loss: 0.4254 - accuracy: 0.7930 - val_loss: 0.3950 - val_accuracy: 0.8105 - lr: 3.6788e-05\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 5s 811ms/step - loss: 0.4187 - accuracy: 0.8032 - val_loss: 0.4054 - val_accuracy: 0.8018 - lr: 3.6788e-05\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 5s 799ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.3836 - val_accuracy: 0.8213 - lr: 3.6788e-05\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 6s 977ms/step - loss: 0.4213 - accuracy: 0.8069 - val_loss: 0.3725 - val_accuracy: 0.8291 - lr: 3.6788e-05\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 5s 871ms/step - loss: 0.4168 - accuracy: 0.8026 - val_loss: 0.3980 - val_accuracy: 0.8076 - lr: 3.6788e-05\n"
     ]
    }
   ],
   "source": [
    "history_inception = model_inceptionv3.fit(\n",
    "    train_generator,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=training_steps,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[model_checkpoint_callback, lr_scheduler],\n",
    "    # callbacks=[tensorboard],\n",
    "    #class_weight=class_weight,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2270 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = create_testgenerator(\n",
    "    TEST_PATH,\n",
    "    class_mode=class_mode,\n",
    "    preprocessing_function=keras.applications.inception_v3.preprocess_input,\n",
    "    image_size=IMG_SIZE\n",
    ")\n",
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_inceptionv3 = load_model(\n",
    "#     f\"{models_path}/classification/inceptionV3_{NUM_EPOCHS}epocas_{len(model_inceptionv3.layers)}capas_lr_{str(LR)}.h5\",\n",
    "#     compile=False\n",
    "# )\n",
    "model_name = 'inceptionV3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96380,
     "status": "ok",
     "timestamp": 1610027733019,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "tj9AezQUnvoW",
    "outputId": "010bd8e7-53bc-422a-8e0c-2d48652becd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270/2270 [==============================] - 34s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = make_prediction(model_inceptionv3, test_generator, class_mode=class_mode, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUpzt-urX2um"
   },
   "source": [
    "# Vgg19\n",
    "The network is trained using the VGG19 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6618 images belonging to 2 classes.\n",
      "Found 1653 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = create_datagenerators(TRAIN_PATH, preprocessing_function=keras.applications.vgg19.preprocess_input)\n",
    "\n",
    "training_steps = train_generator.n//train_generator.batch_size\n",
    "validation_steps = val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = f\"{models_path}/classification/vgg19_{NUM_EPOCHS}epocas_{len(model_vgg19.layers)}capas_lr_{str(LR)}.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9532724,
     "status": "ok",
     "timestamp": 1611347109143,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "cE9V748HYBIJ",
    "outputId": "643968e9-8b5a-4853-b8b0-f745ce30b35d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "6/6 [==============================] - 15s 1s/step - loss: 3.5686 - accuracy: 0.5187 - val_loss: 0.6699 - val_accuracy: 0.6240 - lr: 3.3287e-05\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 3.0256 - accuracy: 0.5156 - val_loss: 0.6836 - val_accuracy: 0.5986 - lr: 3.3287e-05\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 6s 992ms/step - loss: 2.5896 - accuracy: 0.5356 - val_loss: 0.6764 - val_accuracy: 0.6201 - lr: 3.3287e-05\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.3002 - accuracy: 0.5374 - val_loss: 0.6376 - val_accuracy: 0.6621 - lr: 3.3287e-05\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.1370 - accuracy: 0.5279 - val_loss: 0.5906 - val_accuracy: 0.7012 - lr: 3.3287e-05\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8238 - accuracy: 0.5552 - val_loss: 0.5427 - val_accuracy: 0.7275 - lr: 3.3287e-05\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6535 - accuracy: 0.5629 - val_loss: 0.5299 - val_accuracy: 0.7383 - lr: 3.3287e-05\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5645 - accuracy: 0.5629 - val_loss: 0.5165 - val_accuracy: 0.7441 - lr: 3.3287e-05\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 6s 947ms/step - loss: 1.3944 - accuracy: 0.5747 - val_loss: 0.5210 - val_accuracy: 0.7363 - lr: 3.3287e-05\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 5s 942ms/step - loss: 1.3458 - accuracy: 0.5719 - val_loss: 0.5121 - val_accuracy: 0.7441 - lr: 3.3287e-05\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 5s 913ms/step - loss: 1.2850 - accuracy: 0.5735 - val_loss: 0.5107 - val_accuracy: 0.7422 - lr: 3.0119e-05\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.2105 - accuracy: 0.5807 - val_loss: 0.5001 - val_accuracy: 0.7500 - lr: 3.0119e-05\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 5s 936ms/step - loss: 1.1462 - accuracy: 0.5897 - val_loss: 0.5095 - val_accuracy: 0.7373 - lr: 3.0119e-05\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.1526 - accuracy: 0.5715 - val_loss: 0.4955 - val_accuracy: 0.7520 - lr: 3.0119e-05\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 6s 936ms/step - loss: 1.1052 - accuracy: 0.5781 - val_loss: 0.4983 - val_accuracy: 0.7393 - lr: 3.0119e-05\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.0588 - accuracy: 0.5876 - val_loss: 0.4912 - val_accuracy: 0.7549 - lr: 3.0119e-05\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 5s 1s/step - loss: 1.0047 - accuracy: 0.5872 - val_loss: 0.4924 - val_accuracy: 0.7480 - lr: 3.0119e-05\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.9927 - accuracy: 0.5939 - val_loss: 0.4907 - val_accuracy: 0.7559 - lr: 3.0119e-05\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.9544 - accuracy: 0.5903 - val_loss: 0.4653 - val_accuracy: 0.7852 - lr: 3.0119e-05\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 5s 927ms/step - loss: 0.9267 - accuracy: 0.6005 - val_loss: 0.4839 - val_accuracy: 0.7607 - lr: 3.0119e-05\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.8888 - accuracy: 0.5986 - val_loss: 0.4754 - val_accuracy: 0.7754 - lr: 2.7253e-05\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.8944 - accuracy: 0.5976 - val_loss: 0.4810 - val_accuracy: 0.7725 - lr: 2.7253e-05\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 6s 966ms/step - loss: 0.8887 - accuracy: 0.5937 - val_loss: 0.4698 - val_accuracy: 0.7812 - lr: 2.7253e-05\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 6s 959ms/step - loss: 0.8661 - accuracy: 0.6003 - val_loss: 0.4773 - val_accuracy: 0.7715 - lr: 2.7253e-05\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.8398 - accuracy: 0.6067 - val_loss: 0.4724 - val_accuracy: 0.7783 - lr: 2.7253e-05\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.8236 - accuracy: 0.6008 - val_loss: 0.4716 - val_accuracy: 0.7881 - lr: 2.7253e-05\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 5s 936ms/step - loss: 0.7909 - accuracy: 0.6167 - val_loss: 0.4701 - val_accuracy: 0.7852 - lr: 2.7253e-05\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 6s 932ms/step - loss: 0.8115 - accuracy: 0.6040 - val_loss: 0.4742 - val_accuracy: 0.7715 - lr: 2.7253e-05\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.7908 - accuracy: 0.6092 - val_loss: 0.4824 - val_accuracy: 0.7676 - lr: 2.7253e-05\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 6s 980ms/step - loss: 0.7659 - accuracy: 0.6110 - val_loss: 0.4810 - val_accuracy: 0.7734 - lr: 2.7253e-05\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.7473 - accuracy: 0.6124 - val_loss: 0.4693 - val_accuracy: 0.7900 - lr: 2.4660e-05\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.7609 - accuracy: 0.6117 - val_loss: 0.4657 - val_accuracy: 0.7920 - lr: 2.4660e-05\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 6s 952ms/step - loss: 0.7646 - accuracy: 0.6037 - val_loss: 0.4687 - val_accuracy: 0.7852 - lr: 2.4660e-05\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 6s 984ms/step - loss: 0.7545 - accuracy: 0.6089 - val_loss: 0.4683 - val_accuracy: 0.7803 - lr: 2.4660e-05\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 6s 992ms/step - loss: 0.7453 - accuracy: 0.6079 - val_loss: 0.4759 - val_accuracy: 0.7764 - lr: 2.4660e-05\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.7484 - accuracy: 0.6053 - val_loss: 0.4647 - val_accuracy: 0.7949 - lr: 2.4660e-05\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.7336 - accuracy: 0.6176 - val_loss: 0.4651 - val_accuracy: 0.7979 - lr: 2.4660e-05\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 5s 935ms/step - loss: 0.7120 - accuracy: 0.6198 - val_loss: 0.4658 - val_accuracy: 0.7891 - lr: 2.4660e-05\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.7102 - accuracy: 0.6185 - val_loss: 0.4707 - val_accuracy: 0.7910 - lr: 2.4660e-05\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 5s 947ms/step - loss: 0.6997 - accuracy: 0.6212 - val_loss: 0.4629 - val_accuracy: 0.7969 - lr: 2.4660e-05\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 5s 927ms/step - loss: 0.7133 - accuracy: 0.6319 - val_loss: 0.4772 - val_accuracy: 0.7852 - lr: 2.2313e-05\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 6s 981ms/step - loss: 0.6839 - accuracy: 0.6276 - val_loss: 0.4693 - val_accuracy: 0.7939 - lr: 2.2313e-05\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6782 - accuracy: 0.6323 - val_loss: 0.4627 - val_accuracy: 0.8008 - lr: 2.2313e-05\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 6s 989ms/step - loss: 0.6939 - accuracy: 0.6273 - val_loss: 0.4693 - val_accuracy: 0.8008 - lr: 2.2313e-05\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 6s 978ms/step - loss: 0.6866 - accuracy: 0.6269 - val_loss: 0.4645 - val_accuracy: 0.7998 - lr: 2.2313e-05\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.6846 - accuracy: 0.6221 - val_loss: 0.4541 - val_accuracy: 0.8057 - lr: 2.2313e-05\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6867 - accuracy: 0.6123 - val_loss: 0.4648 - val_accuracy: 0.8066 - lr: 2.2313e-05\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.6751 - accuracy: 0.6248 - val_loss: 0.4683 - val_accuracy: 0.7959 - lr: 2.2313e-05\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6720 - accuracy: 0.6269 - val_loss: 0.4584 - val_accuracy: 0.8115 - lr: 2.2313e-05\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 6s 952ms/step - loss: 0.6711 - accuracy: 0.6183 - val_loss: 0.4663 - val_accuracy: 0.7969 - lr: 2.2313e-05\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 6s 983ms/step - loss: 0.6681 - accuracy: 0.6314 - val_loss: 0.4582 - val_accuracy: 0.8018 - lr: 2.0190e-05\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 6s 949ms/step - loss: 0.6762 - accuracy: 0.6242 - val_loss: 0.4621 - val_accuracy: 0.8037 - lr: 2.0190e-05\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6608 - accuracy: 0.6226 - val_loss: 0.4583 - val_accuracy: 0.8145 - lr: 2.0190e-05\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 6s 948ms/step - loss: 0.6624 - accuracy: 0.6332 - val_loss: 0.4632 - val_accuracy: 0.8066 - lr: 2.0190e-05\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 5s 945ms/step - loss: 0.6634 - accuracy: 0.6301 - val_loss: 0.4681 - val_accuracy: 0.7979 - lr: 2.0190e-05\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 6s 965ms/step - loss: 0.6533 - accuracy: 0.6344 - val_loss: 0.4638 - val_accuracy: 0.8057 - lr: 2.0190e-05\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 6s 967ms/step - loss: 0.6616 - accuracy: 0.6271 - val_loss: 0.4533 - val_accuracy: 0.8125 - lr: 2.0190e-05\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 6s 941ms/step - loss: 0.6504 - accuracy: 0.6269 - val_loss: 0.4642 - val_accuracy: 0.8047 - lr: 2.0190e-05\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 5s 944ms/step - loss: 0.6547 - accuracy: 0.6241 - val_loss: 0.4602 - val_accuracy: 0.8066 - lr: 2.0190e-05\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 6s 987ms/step - loss: 0.6488 - accuracy: 0.6221 - val_loss: 0.4599 - val_accuracy: 0.8066 - lr: 2.0190e-05\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 6s 947ms/step - loss: 0.6533 - accuracy: 0.6269 - val_loss: 0.4609 - val_accuracy: 0.8037 - lr: 1.8268e-05\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 6s 954ms/step - loss: 0.6214 - accuracy: 0.6421 - val_loss: 0.4614 - val_accuracy: 0.8018 - lr: 1.8268e-05\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 6s 977ms/step - loss: 0.6343 - accuracy: 0.6398 - val_loss: 0.4541 - val_accuracy: 0.8047 - lr: 1.8268e-05\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.6500 - accuracy: 0.6307 - val_loss: 0.4579 - val_accuracy: 0.8105 - lr: 1.8268e-05\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 6s 947ms/step - loss: 0.6424 - accuracy: 0.6287 - val_loss: 0.4620 - val_accuracy: 0.8037 - lr: 1.8268e-05\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 6s 960ms/step - loss: 0.6340 - accuracy: 0.6369 - val_loss: 0.4607 - val_accuracy: 0.8018 - lr: 1.8268e-05\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 6s 964ms/step - loss: 0.6408 - accuracy: 0.6323 - val_loss: 0.4617 - val_accuracy: 0.8066 - lr: 1.8268e-05\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6268 - accuracy: 0.6414 - val_loss: 0.4495 - val_accuracy: 0.8105 - lr: 1.8268e-05\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6398 - accuracy: 0.6262 - val_loss: 0.4571 - val_accuracy: 0.8164 - lr: 1.8268e-05\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 5s 927ms/step - loss: 0.6474 - accuracy: 0.6232 - val_loss: 0.4581 - val_accuracy: 0.8086 - lr: 1.8268e-05\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 6s 963ms/step - loss: 0.6180 - accuracy: 0.6373 - val_loss: 0.4650 - val_accuracy: 0.7998 - lr: 1.6530e-05\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 6s 961ms/step - loss: 0.6294 - accuracy: 0.6328 - val_loss: 0.4622 - val_accuracy: 0.8096 - lr: 1.6530e-05\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 6s 947ms/step - loss: 0.6488 - accuracy: 0.6323 - val_loss: 0.4646 - val_accuracy: 0.7930 - lr: 1.6530e-05\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6278 - accuracy: 0.6419 - val_loss: 0.4584 - val_accuracy: 0.8203 - lr: 1.6530e-05\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 6s 977ms/step - loss: 0.6193 - accuracy: 0.6425 - val_loss: 0.4584 - val_accuracy: 0.8076 - lr: 1.6530e-05\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6227 - accuracy: 0.6348 - val_loss: 0.4594 - val_accuracy: 0.8213 - lr: 1.6530e-05\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 6s 939ms/step - loss: 0.6307 - accuracy: 0.6409 - val_loss: 0.4564 - val_accuracy: 0.8203 - lr: 1.6530e-05\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 6s 952ms/step - loss: 0.6203 - accuracy: 0.6351 - val_loss: 0.4664 - val_accuracy: 0.7988 - lr: 1.6530e-05\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 6s 950ms/step - loss: 0.6187 - accuracy: 0.6359 - val_loss: 0.4600 - val_accuracy: 0.8076 - lr: 1.6530e-05\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 5s 943ms/step - loss: 0.6258 - accuracy: 0.6380 - val_loss: 0.4607 - val_accuracy: 0.8115 - lr: 1.6530e-05\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6346 - accuracy: 0.6337 - val_loss: 0.4556 - val_accuracy: 0.8223 - lr: 1.4957e-05\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 6s 999ms/step - loss: 0.6282 - accuracy: 0.6303 - val_loss: 0.4578 - val_accuracy: 0.8135 - lr: 1.4957e-05\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6260 - accuracy: 0.6328 - val_loss: 0.4509 - val_accuracy: 0.8184 - lr: 1.4957e-05\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 6s 999ms/step - loss: 0.6177 - accuracy: 0.6230 - val_loss: 0.4672 - val_accuracy: 0.8027 - lr: 1.4957e-05\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6159 - accuracy: 0.6459 - val_loss: 0.4557 - val_accuracy: 0.8174 - lr: 1.4957e-05\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6193 - accuracy: 0.6460 - val_loss: 0.4514 - val_accuracy: 0.8145 - lr: 1.4957e-05\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6169 - accuracy: 0.6419 - val_loss: 0.4523 - val_accuracy: 0.8125 - lr: 1.4957e-05\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6086 - accuracy: 0.6430 - val_loss: 0.4542 - val_accuracy: 0.8213 - lr: 1.4957e-05\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6087 - accuracy: 0.6457 - val_loss: 0.4529 - val_accuracy: 0.8164 - lr: 1.4957e-05\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6132 - accuracy: 0.6412 - val_loss: 0.4541 - val_accuracy: 0.8125 - lr: 1.4957e-05\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.6147 - accuracy: 0.6294 - val_loss: 0.4480 - val_accuracy: 0.8242 - lr: 1.3534e-05\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.6091 - accuracy: 0.6373 - val_loss: 0.4539 - val_accuracy: 0.8125 - lr: 1.3534e-05\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6119 - accuracy: 0.6410 - val_loss: 0.4525 - val_accuracy: 0.8223 - lr: 1.3534e-05\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.5968 - accuracy: 0.6410 - val_loss: 0.4571 - val_accuracy: 0.8164 - lr: 1.3534e-05\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6080 - accuracy: 0.6369 - val_loss: 0.4584 - val_accuracy: 0.8105 - lr: 1.3534e-05\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.5997 - accuracy: 0.6523 - val_loss: 0.4568 - val_accuracy: 0.8105 - lr: 1.3534e-05\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6109 - accuracy: 0.6400 - val_loss: 0.4587 - val_accuracy: 0.7979 - lr: 1.3534e-05\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6020 - accuracy: 0.6598 - val_loss: 0.4512 - val_accuracy: 0.8193 - lr: 1.3534e-05\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.5968 - accuracy: 0.6502 - val_loss: 0.4531 - val_accuracy: 0.8135 - lr: 1.3534e-05\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.6130 - accuracy: 0.6403 - val_loss: 0.4615 - val_accuracy: 0.8057 - lr: 1.3534e-05\n"
     ]
    }
   ],
   "source": [
    "# model_vgg19.load_weights(\"/content/drive/MyDrive/integradora_fiec/modelo_clasificacion/vgg19_40_epocas_15capas_lr_{str(LR)}.h5\")\n",
    "history_vgg19 = model_vgg19.fit(\n",
    "    train_generator,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=training_steps,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[model_checkpoint_callback, lr_scheduler],\n",
    "    #class_weight=class_weight,\n",
    "     shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2291 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = create_testgenerator(\n",
    "    TEST_PATH,\n",
    "    class_mode=class_mode,\n",
    "    preprocessing_function=keras.applications.vgg19.preprocess_input,\n",
    "    image_size=IMG_SIZE\n",
    ")\n",
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_vgg19 = load_model(\n",
    "#     f'{models_path}/classification/vgg19_{NUM_EPOCHS}epocas_{len(model_vgg19.layers)}capas_lr_{str(LR)}.h5',\n",
    "#     compile=False\n",
    "# )\n",
    "model_name = 'vgg19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 448041,
     "status": "ok",
     "timestamp": 1610018701571,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "9XdFhw8pRG86",
    "outputId": "ba51d5df-8a3d-4b21-9e80-bc9be072423b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 12s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = make_prediction(model_vgg19, test_generator, class_mode=class_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Prn2QajeFWc"
   },
   "source": [
    "# ResNet50v2\n",
    "The network is trained using the ResNet50v2 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15029 images belonging to 2 classes.\n",
      "Found 3756 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = create_datagenerators(TRAIN_PATH, preprocessing_function=keras.applications.resnet_v2.preprocess_input)\n",
    "\n",
    "training_steps = train_generator.n//train_generator.batch_size\n",
    "validation_steps = val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "bEELaFlGzIgG"
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = f\"{models_path}/classification/resnet50v2_{NUM_EPOCHS}epocas_{len(model_resnet50v2.layers)}capas_lr_{str(LR)}.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 629844,
     "status": "ok",
     "timestamp": 1610053268864,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "2ix02sloeOIL",
    "outputId": "81ba3bb6-c587-4913-a2a5-6b0b24b4f542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "14/14 [==============================] - ETA: 0s - loss: 2.1544 - accuracy: 0.5069"
     ]
    }
   ],
   "source": [
    "history_resnet = model_resnet50v2.fit(train_generator,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=training_steps,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[model_checkpoint_callback, lr_scheduler],\n",
    "    #class_weight=class_weight,\n",
    "    shuffle=True\n",
    "                                   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = create_testgenerator(\n",
    "    TEST_PATH,\n",
    "    class_mode=class_mode,\n",
    "    preprocessing_function=keras.applications.resnet_v2.preprocess_input,\n",
    "    image_size=IMG_SIZE\n",
    ")\n",
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159568,
     "status": "ok",
     "timestamp": 1610041873640,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "M-vGR-MjbSuW",
    "outputId": "cd9841a0-7299-4c1e-9e79-28f2d36f039f"
   },
   "outputs": [],
   "source": [
    "# model_resnet50v2 = load_model(\n",
    "#     f\"{models_path}/classification/resnet50v2_{NUM_EPOCHS}epocas_{len(model_resnet50v2.layers)}capas_lr_{str(LR)}.h5\",\n",
    "#     compile=False\n",
    "# )\n",
    "model_name = 'resnet50v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = make_prediction(model_resnet50v2, test_generator, class_mode=class_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fxTHRm1ep9Y"
   },
   "source": [
    "# MobileNetv2\n",
    "The network is trained using the MobileNetv2 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, val_generator = create_datagenerators(TRAIN_PATH, preprocessing_function=keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "training_steps = train_generator.n//train_generator.batch_size\n",
    "validation_steps = val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = f\"{models_path}/classification/mobilenetv2_{NUM_EPOCHS}epocas_{len(model_mobilenetv2.layers)}capas_lr_{str(LR)}.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1041688,
     "status": "ok",
     "timestamp": 1610055038874,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "wnlWEp8reuKc",
    "outputId": "cad0fdb1-28ff-402d-e771-52606978eeac"
   },
   "outputs": [],
   "source": [
    "history_mobile = model_mobilenetv2.fit(\n",
    "    train_generator,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=training_steps,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[model_checkpoint_callback, lr_scheduler],\n",
    "    #class_weight=class_weight,\n",
    "     shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = create_testgenerator(\n",
    "    TEST_PATH,\n",
    "    class_mode=class_mode,\n",
    "    preprocessing_function=keras.applications.mobilenet_v2.preprocess_input,\n",
    "    image_size=IMG_SIZE\n",
    ")\n",
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159568,
     "status": "ok",
     "timestamp": 1610041873640,
     "user": {
      "displayName": "Alex Dario Macas Alcocer",
      "photoUrl": "",
      "userId": "07567273049273138555"
     },
     "user_tz": 300
    },
    "id": "M-vGR-MjbSuW",
    "outputId": "cd9841a0-7299-4c1e-9e79-28f2d36f039f"
   },
   "outputs": [],
   "source": [
    "# model_mobilenetv2 = load_model(\n",
    "#     f\"{models_path}/classification/mobilenetv2_{NUM_EPOCHS}epocas_{len(model_mobilenetv2.layers)}capas_lr_{str(LR)}.h5\",\n",
    "#     compile=False\n",
    "# )\n",
    "model_name = 'mobilenetV2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = make_prediction(model_mobilenetv2, test_generator, class_mode=class_mode)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocesing_01_classification_all_slices_mask.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
