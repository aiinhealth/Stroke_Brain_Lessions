{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2XvrOWkyk9O"
   },
   "source": [
    "First create a direct access to /datasets folder in your personal drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21364,
     "status": "ok",
     "timestamp": 1685857959915,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "eMNWO08O81RZ",
    "outputId": "3db3091e-cfa5-4a64-fd98-316dda673fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount drive if needed\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8rt_QUUthFp"
   },
   "source": [
    "\n",
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31384,
     "status": "ok",
     "timestamp": 1685858489375,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "Bdm-G9y_1Wrw",
    "outputId": "e686530d-18d0-4633-d17a-cb169678ef5e"
   },
   "outputs": [],
   "source": [
    "# ! pip install SimpleITK\n",
    "# ! pip install antspyx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4B0BhRTnxlxj"
   },
   "source": [
    "\n",
    "## Load images to current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38863,
     "status": "ok",
     "timestamp": 1685755447113,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "GhAcoJXWxqgK",
    "outputId": "72117645-29d6-46e1-cae5-152c1b8e4df1"
   },
   "outputs": [],
   "source": [
    "# ! mkdir -v data\n",
    "# ! unzip \"/content/drive/MyDrive/integradora_fiec/datasets/NATIVE.zip\" -d \"/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nUkyINb3zCR"
   },
   "source": [
    "## Preprocessing steps functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14041,
     "status": "ok",
     "timestamp": 1685817217259,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "0rHZzByP5XeA",
    "outputId": "a722cf1b-2e3e-41ce-94eb-cdc4b313a359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AntsPy version = 0.3.8\n",
      "SimpleITK version = 2.2.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import ants\n",
    "import SimpleITK as sitk\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "print(f'AntsPy version = {ants.__version__}')\n",
    "print(f'SimpleITK version = {sitk.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "id8_NUqU4iHV"
   },
   "outputs": [],
   "source": [
    "mni_T1_path = TEMPLATE_PATH = '/content/drive/MyDrive/integradora_fiec/datasets/templates/mni_icbm152_t1_tal_nlin_sym_09a.nii'\n",
    "\n",
    "def load_template_ants() -> ants.ANTsImage:\n",
    "    \"\"\"\n",
    "    Loads the template image using the ANTs library.\n",
    "\n",
    "    Returns:\n",
    "        ants.ANTsImage: The loaded template image as an ANTsImage object.\n",
    "    \"\"\"\n",
    "    template_img_ants = ants.image_read(TEMPLATE_PATH)\n",
    "    return template_img_ants\n",
    "\n",
    "def load_img_ants(path: str) -> ants.ANTsImage:\n",
    "    \"\"\"\n",
    "    Loads an image from the specified file path using the ANTs library.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path of the image to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        ants.ANTsImage: The loaded image as an ANTsImage object.\n",
    "    \"\"\"\n",
    "    raw_img_ants = ants.image_read(path)\n",
    "    return raw_img_ants\n",
    "\n",
    "def register_to_mni(img: ants.ANTsImage, mask: ants.ANTsImage) -> ants.ANTsImage:\n",
    "    \"\"\"\n",
    "    Registers an MRI image and its associated mask to the MNI space using ANTs library.\n",
    "\n",
    "    Args:\n",
    "        img (ants.ANTsImage): The MRI image to be registered.\n",
    "        mask (ants.ANTsImage): The mask associated with the MRI image.\n",
    "\n",
    "    Returns:\n",
    "        ants.ANTsImage: The registered MRI image in MNI space.\n",
    "        ants.ANTsImage: The registered mask in MNI space.\n",
    "    \"\"\"\n",
    "    template_img = load_template_ants()\n",
    "    transformation = ants.registration(fixed=template_img, moving=img, type_of_transform='SyN')\n",
    "\n",
    "    img_registered = transformation['warpedmovout']\n",
    "  \n",
    "    mask_registered = ants.apply_transforms(fixed=template_img,moving=mask,transformlist=transformation['fwdtransforms'])\n",
    "    return img_registered, mask_registered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3nnbYgj4qnZ"
   },
   "source": [
    "## Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3r_861Ot4svp"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "xpaths = sorted(glob(f'/data/NATIVE/*/*/*01.nii.gz') )\n",
    "ypaths = sorted(glob(f'/data/NATIVE/*/*/*01_LesionSmooth.nii.gz'))\n",
    "assert len(xpaths) == len(ypaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1685756249149,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "2_L0ZjyRMYer",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "47af604b-02e7-4e03-f935-35acd3ab9ef9"
   },
   "outputs": [],
   "source": [
    "print(\"Number of samples:\", len(xpaths))\n",
    "for input_path, target_path in zip(xpaths, ypaths):\n",
    "    print(input_path[-35:], \"|\", target_path[-48:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3740194,
     "status": "ok",
     "timestamp": 1685780553602,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "eCWkTx3B5vfL",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "fddfe2c1-76af-4d57-cb2a-bfc8e0445dcb"
   },
   "outputs": [],
   "source": [
    "# Loop over the pairs of input and target file paths and perform registration to MNI space\n",
    "for i,(xpath, ypath) in enumerate(zip(xpaths, ypaths)):\n",
    "  # Extract folder path and file name for the registered images\n",
    "  folder = xpath[:-20]\n",
    "  file_name = xpath[:-7][-13:]\n",
    "  x_registered_path = folder + file_name + '_registered.nii.gz'\n",
    "  y_registered_path = folder + file_name + '_LesionSmooth_registered.nii.gz'\n",
    "\n",
    "  # Load the input and target images using ANTs\n",
    "  x3d = load_img_ants(xpath)\n",
    "  y3d = load_img_ants(ypath)\n",
    "\n",
    "  # Perform registration to MNI space\n",
    "  x3d_registered, y3d_registered = register_to_mni(img=x3d,mask=y3d)\n",
    "\n",
    "  # Print the current iteration and the paths for the registered images\n",
    "  print(i, x_registered_path)\n",
    "  print(i, y_registered_path)\n",
    "  \n",
    "  # Save the registered images to their respective paths\n",
    "  x3d_registered.to_file(x_registered_path)\n",
    "  y3d_registered.to_file(y_registered_path)\n",
    "\n",
    "  #if i == 0 : break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmgC4KnjDc47"
   },
   "source": [
    "## Bias Field Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RLqPRCMDgnv"
   },
   "outputs": [],
   "source": [
    "xpaths = sorted(glob(f'/data/NATIVE/*/*/*01_registered.nii.gz') )\n",
    "ypaths = sorted(glob(f'/data/NATIVE/*/*/*01_LesionSmooth_registered.nii.gz'))\n",
    "assert len(xpaths) == len(ypaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1685780553605,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "pL92X1T0DaUQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2f9bb4a8-988b-441d-c318-02cc65e3ce71"
   },
   "outputs": [],
   "source": [
    "print(\"Number of samples:\", len(xpaths))\n",
    "for input_path, target_path in zip(xpaths, ypaths):\n",
    "    print(input_path[-35:], \"|\", target_path[-48:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkXbZBb-Do1b"
   },
   "outputs": [],
   "source": [
    "def bias_field_correction(img: sitk.Image) -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Perform bias field correction on the input image using N4BiasFieldCorrection.\n",
    "\n",
    "    Args:\n",
    "        img (sitk.Image): The input image to be bias corrected.\n",
    "\n",
    "    Returns:\n",
    "        sitk.Image: The bias-corrected image.\n",
    "    \"\"\"\n",
    "    # Thresholding and rescaling the input image for creating the head mask\n",
    "    head_mask = sitk.RescaleIntensity(img, 0, 255)\n",
    "    head_mask = sitk.LiThreshold(head_mask,0,1)\n",
    "\n",
    "    # Shrinking the input image and head mask for faster processing\n",
    "    shrinkFactor = 4\n",
    "    inputImage = img\n",
    "    inputImage = sitk.Shrink( img, [ shrinkFactor ] * inputImage.GetDimension() )\n",
    "    maskImage = sitk.Shrink( head_mask, [ shrinkFactor ] * inputImage.GetDimension() )\n",
    "\n",
    "    # Applying N4BiasFieldCorrectionImageFilter for bias field correction\n",
    "    bias_corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    bias_corrector.Execute(inputImage, maskImage)\n",
    "\n",
    "    # Retrieving the log bias field and correcting the image at full resolution\n",
    "    log_bias_field = bias_corrector.GetLogBiasFieldAsImage(img)\n",
    "    result = img / sitk.Exp( log_bias_field ) # corrected img at full resolution\n",
    "\n",
    "    # The output of division has a 64 pixel type, we cast it to float32 to maintain compatibility\n",
    "    result = sitk.Cast(result, sitk.sitkFloat32)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def load_img_sitk(path: str) -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Load an image using SimpleITK (sitk) and return it.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        sitk.Image: The loaded image as a SimpleITK Image object.\n",
    "    \"\"\"\n",
    "    raw_img_sitk = sitk.ReadImage(path, sitk.sitkFloat32)\n",
    "    return raw_img_sitk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2768150,
     "status": "ok",
     "timestamp": 1685783321751,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "Ye88JcOcEPIi",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "28a86b23-7d12-4bbc-8262-9af4aa1475d7"
   },
   "outputs": [],
   "source": [
    "for i,(xpath, ypath) in enumerate(zip(xpaths, ypaths)):\n",
    "  # Extract folder and file name information from the input and target file paths\n",
    "  folder = xpath[:-20]\n",
    "  file_name = xpath[:-7][-13:]\n",
    "  # Create the output path for the bias field corrected image\n",
    "  x_out_path = folder + file_name + '_BF.nii.gz'\n",
    "\n",
    "  x3d = load_img_sitk(xpath)\n",
    "  x3d_bf_corrected = bias_field_correction(x3d)\n",
    "\n",
    "  sitk.WriteImage(x3d_bf_corrected, x_out_path)\n",
    "\n",
    "  # Print the progress (index) and the output path of the bias field corrected image\n",
    "  print(i, x_out_path)\n",
    "\n",
    "  #if i == 0 : break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-m0hqWbFmyb"
   },
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nn2SgDqQXTLr"
   },
   "outputs": [],
   "source": [
    "xpaths = sorted(glob(f'/data/NATIVE/*/*/*01_registered_BF.nii.gz') )\n",
    "ypaths = sorted(glob(f'/data/NATIVE/*/*/*01_LesionSmooth_registered.nii.gz'))\n",
    "assert len(xpaths) == len(ypaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBlYCZJEXVir"
   },
   "outputs": [],
   "source": [
    "print(\"Number of samples:\", len(xpaths))\n",
    "for input_path, target_path in zip(xpaths, ypaths):\n",
    "    print(input_path[-35:], \"|\", target_path[-48:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uEzKrrwFpHg"
   },
   "outputs": [],
   "source": [
    "# load mni152 brain mask\n",
    "TEMPLATE_BRAIN_MASK_PATH = '/content/drive/MyDrive/integradora_fiec/datasets/templates/mni_icbm152_t1_tal_nlin_sym_09a_mask.nii'\n",
    "mni152_brain_mask = sitk.ReadImage(TEMPLATE_BRAIN_MASK_PATH, sitk.sitkFloat32)\n",
    "mni152_T1 = sitk.ReadImage(TEMPLATE_PATH, sitk.sitkFloat32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RiCu-67XB7V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def preprocess_ximg(ximg: sitk.Image, flipped = False) -> np.ndarray:\n",
    "  \"\"\"\n",
    "    Preprocess the input image (ximg) using several SimpleITK image processing operations.\n",
    "    \n",
    "    Args:\n",
    "        ximg (sitk.Image): The input image in SimpleITK format.\n",
    "        flipped (bool, optional): Flag to determine whether to flip the image or not.\n",
    "            Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The preprocessed 3D numpy array representing the image.\n",
    "\n",
    "    \"\"\"\n",
    "  # Histogram matching with the MNI152 T1 template\n",
    "  x3d = sitk.HistogramMatching(ximg, mni152_T1)\n",
    "  # Apply brain masking using the MNI152 brain mask\n",
    "  x3d = sitk.Multiply(x3d, mni152_brain_mask)\n",
    "  # Perform Curvature Anisotropic Diffusion for denoising the image\n",
    "  x3d = sitk.CurvatureAnisotropicDiffusion(x3d, conductanceParameter=1, numberOfIterations=1) # denoise a bit\n",
    "  \n",
    "  # Flip the image if specified\n",
    "  if flipped:\n",
    "    x3d = sitk.Flip(x3d,(True, False, False))\n",
    "  \n",
    "  x3d = sitk.GetArrayFromImage(x3d)\n",
    "  x3d = x3d[30:160,4:228,14:190] # crop to size -> (130, 224, 176)\n",
    "  # Normalize the array values to the range [0, 1]\n",
    "  x3d = x3d / 255.0\n",
    "  x3d = np.expand_dims(x3d,3) # add channel -> (130, 224, 176, 1)\n",
    "  # Ensure the array shape is as expected\n",
    "  assert x3d.shape == (130,224,176,1)\n",
    "  return x3d\n",
    "\n",
    "def preprocess_yimg(yimg: sitk.Image, flipped=False) -> np.ndarray:\n",
    "  \"\"\"\n",
    "    Preprocess the target image (yimg) for segmentation using SimpleITK image processing operations.\n",
    "    \n",
    "    Args:\n",
    "        yimg (sitk.Image): The target image in SimpleITK format.\n",
    "        flipped (bool, optional): Flag to determine whether to flip the image or not.\n",
    "            Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The preprocessed 3D numpy array representing the target segmentation.\n",
    "\n",
    "    \"\"\"\n",
    "  y3d = yimg\n",
    "\n",
    "  if flipped:\n",
    "    y3d = sitk.Flip(y3d,(True, False, False))\n",
    "  \n",
    "  y3d = sitk.GetArrayFromImage(y3d)\n",
    "  y3d = y3d[30:160,4:228,14:190] # crop to size -> (130, 224, 176)\n",
    "  y3d = y3d / 255.0\n",
    "  y3d = np.expand_dims(y3d,3) # add channel -> (130, 224, 176, 1)\n",
    "  assert x3d.shape == (130,224,176,1)\n",
    "  return y3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrCYA5cgXPNr"
   },
   "outputs": [],
   "source": [
    "ROW_SIZE = 224 # shapes of model inpput\n",
    "COL_SIZE = 176\n",
    "\n",
    "X = np.empty((0,ROW_SIZE,COL_SIZE,1), dtype=np.float32)\n",
    "Y = np.empty((0,ROW_SIZE,COL_SIZE,1), dtype=np.float32)\n",
    "\n",
    "for i,(xpath, ypath) in enumerate(zip(xpaths, ypaths)):\n",
    "    # Read the input image using SimpleITK\n",
    "    ximg        =   sitk.ReadImage(xpath, sitk.sitkFloat32)\n",
    "    x3d         =  preprocess_ximg(ximg) \n",
    "    #flipped_x3d =  preprocess_ximg(ximg, flipped=True)\n",
    "\n",
    "    yimg        =   sitk.ReadImage(ypath, sitk.sitkFloat32)\n",
    "    y3d         =  preprocess_yimg(yimg) \n",
    "    #flipped_y3d =  preprocess_yimg(yimg, flipped=True)\n",
    "    \n",
    "    #x3d = np.concatenate((x3d, flipped_x3d), axis=0)\n",
    "    #y3d = np.concatenate((y3d, flipped_y3d), axis=0)\n",
    "\n",
    "    #assert x3d.shape  == (260,224,176, 1)\n",
    "    #assert y3d.shape  == (260,224,176, 1)\n",
    "\n",
    "    # Update the main X and Y arrays with the preprocessed images\n",
    "    X = np.concatenate((X, x3d), axis=0)\n",
    "    Y = np.concatenate((Y, y3d), axis=0)\n",
    "\n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1685784751166,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "hDweE5HsXc2z",
    "outputId": "81d800b0-a98a-4ef3-f03d-7987932a8b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37960, 224, 176, 1) (37960, 224, 176, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1685756178595,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "WmpXKtSKZNQI",
    "outputId": "84bf13af-ce4b-4c26-8a1a-78a66365beac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 224, 176)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:,:,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltHhwU2sY0TD"
   },
   "source": [
    "## Double check slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCC2IlRXbUpL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_x2d_marked(x2d,y2d):\n",
    "  \"\"\"\n",
    "    Get the 2D slice of the input image marked by the binary mask of the target image.\n",
    "\n",
    "    Args:\n",
    "        x2d (numpy.ndarray): 2D slice of the input image.\n",
    "        y2d (numpy.ndarray): 2D binary mask of the target image.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The marked 2D slice of the input image.\n",
    "\n",
    "    \"\"\"\n",
    "  dilation_level = 4\n",
    "  # Convert the binary mask to a SimpleITK image and perform binary dilation and contouring\n",
    "  m = (y2d).astype('uint8')\n",
    "  m = sitk.GetImageFromArray(m)\n",
    "  m = sitk.BinaryDilate(m,(dilation_level,1,1))\n",
    "  m = sitk.BinaryContour(m)\n",
    "  # Convert the input image slice to a SimpleITK image and mask it using the binary mask\n",
    "  x2d_marked = sitk.GetImageFromArray(x2d)\n",
    "  x2d_marked = sitk.MaskNegated(x2d_marked, sitk.Cast(m,sitk.sitkFloat32))\n",
    "  # Convert the marked image back to a numpy array\n",
    "  x2d_marked = sitk.GetArrayFromImage(x2d_marked)\n",
    "  return x2d_marked\n",
    "\n",
    "def show_slices(slices: list[np.ndarray], cmap: str ='gray'):\n",
    "  \"\"\" \n",
    "    Function to display a list of image slices (2D arrays). Optimal quantity is three slices.\n",
    "\n",
    "    Args:\n",
    "        slices (list[np.ndarray]): List of 2D arrays representing image slices.\n",
    "        cmap (str, optional): Colormap to use for displaying the slices. Defaults to 'gray'.\n",
    "\n",
    "    \"\"\"\n",
    "  fig, axes = plt.subplots(len(slices), 1, figsize=(15,15))\n",
    "  for i, slice in enumerate(slices):\n",
    "    axes[i].imshow(slice, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1oNkUp28gQYOa209MtAtN4CTh0VjQuxY5"
    },
    "executionInfo": {
     "elapsed": 7085,
     "status": "ok",
     "timestamp": 1685818919125,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "eZaRB9ZobXN2",
    "outputId": "ea37be74-759b-4f90-bd11-58e4813d63cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STEPS = 150\n",
    "c=0\n",
    "for i in range(0,len(X),STEPS):\n",
    "  x, y = X[i], Y[i]\n",
    "  # Check if the Y slice contains only one unique value (segmentation mask)\n",
    "  if len(np.unique(y)) == 1:\n",
    "    continue\n",
    "\n",
    "  # Get the marked version of the X slice using the Y segmentation mask\n",
    "  x2d_marked = get_x2d_marked(x[:,:,0],y[:,:,0])\n",
    "  # Show the slices using the show_slices() function\n",
    "  show_slices([x2d_marked,x[:,:,0]])\n",
    "  c+=1\n",
    "  if c==10:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFrpmprabxsB"
   },
   "source": [
    "## Save training dataset as npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAPpbgVZbreV"
   },
   "outputs": [],
   "source": [
    "from numpy import save\n",
    "# contains data processed from 292 native ATLAS imgs trough: register to mni, bias field, histogram matching, brain extraction, denoise\n",
    "X_output_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_ALL_X.npy'\n",
    "Y_output_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_ALL_Y.npy'\n",
    "\n",
    "\n",
    "save(X_output_path, X)\n",
    "save(Y_output_path, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrrVAd_tdnYB"
   },
   "source": [
    "## Load first train set [JUMP HERE IF DATA AVAILABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkMS-YnjdpD2"
   },
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "X_input_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_ALL_X.npy'\n",
    "Y_input_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_ALL_Y.npy'\n",
    "\n",
    "X = load(X_input_path)\n",
    "Y = load(Y_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1685858155919,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "iMQcUwCQd6mi",
    "outputId": "352cba88-0dad-4e3c-c4d4-44c410abd9d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37960, 224, 176, 1) (37960, 224, 176, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-Qv1SPrjqCc"
   },
   "source": [
    "## Make flip operation to double dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8537,
     "status": "ok",
     "timestamp": 1685858583956,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "089P5Hj3Zt_G",
    "outputId": "0fa05826-8349-455d-83b1-14a127abe66f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ROW_SIZE = 224 # shapes of model inpput\n",
    "COL_SIZE = 176\n",
    "\n",
    "# need to allocate array before hand for efficient usage of memory\n",
    "X_flipped = np.zeros((37960,ROW_SIZE,COL_SIZE,1), dtype=np.float32)\n",
    "Y_flipped = np.zeros((37960,ROW_SIZE,COL_SIZE,1), dtype=np.float32)\n",
    "\n",
    "for i, idx in enumerate(range(0, len(X))):\n",
    "  xtemp = np.flip(X[idx,:,:,0], axis=1)\n",
    "  ytemp = np.flip(Y[idx,:,:,0], axis=1)\n",
    "  \n",
    "  #xtemp = np.expand_dims(xtemp,2) # add channel -> (224, 176, 1)\n",
    "  #ytemp = np.expand_dims(ytemp,2)\n",
    "\n",
    "  X_flipped[idx] = np.expand_dims(xtemp,2) \n",
    "  Y_flipped[idx] = np.expand_dims(ytemp,2) \n",
    "\n",
    "  #if i == 100 : break\n",
    "  if i % 130 == 0:\n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1685858590441,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "oxo6-9Jdh3LA",
    "outputId": "63c8d734-ff99-4eb6-dd97-a5c3ae3047eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37960, 224, 176, 1) (37960, 224, 176, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_flipped.shape, Y_flipped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hf2M5rq97U0l"
   },
   "outputs": [],
   "source": [
    "from numpy import save\n",
    "# contains data processed from 292 native ATLAS imgs trough: register to mni, bias field, histogram matching, brain extraction, denoise\n",
    "X_output_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_ALL_FLIPPED_X.npy'\n",
    "Y_output_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_ALL_FLIPPED_Y.npy'\n",
    "\n",
    "save(X_output_path, X_flipped)\n",
    "save(Y_output_path, Y_flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHlPaC-Sah1d"
   },
   "source": [
    "## Double check slices flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GVA03xgiHUA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "def get_x2d_marked(x2d,y2d):\n",
    "  \"\"\"\n",
    "    Generate a marked version of a 2D image slice based on the corresponding 2D segmentation mask.\n",
    "\n",
    "    Args:\n",
    "        x2d (numpy.ndarray): The 2D image slice.\n",
    "        y2d (numpy.ndarray): The 2D segmentation mask.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The marked version of the 2D image slice.\n",
    "\n",
    "    \"\"\"\n",
    "  dilation_level = 4\n",
    "  m = (y2d).astype('uint8')\n",
    "  m = sitk.GetImageFromArray(m)\n",
    "  m = sitk.BinaryDilate(m,(dilation_level,1,1))\n",
    "  m = sitk.BinaryContour(m)\n",
    "\n",
    "  x2d_marked = sitk.GetImageFromArray(x2d)\n",
    "  x2d_marked = sitk.MaskNegated(x2d_marked, sitk.Cast(m,sitk.sitkFloat32))\n",
    "  x2d_marked = sitk.GetArrayFromImage(x2d_marked)\n",
    "  return x2d_marked\n",
    "\n",
    "def show_slices(slices: list[np.ndarray], cmap: str ='gray'):\n",
    "  \"\"\"\n",
    "    Display a list of 2D image slices using Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        slices (list of numpy.ndarray): The list of 2D image slices to display.\n",
    "        cmap (str, optional): The color map to use for displaying the images. Defaults to 'gray'.\n",
    "\n",
    "    \"\"\"\n",
    "  fig, axes = plt.subplots(len(slices), 1, figsize=(15,15))\n",
    "  for i, slice in enumerate(slices):\n",
    "    axes[i].imshow(slice, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1tvbIQiHfkUcf_R6AduevVXJMpASIfpyE"
    },
    "executionInfo": {
     "elapsed": 8072,
     "status": "ok",
     "timestamp": 1685858606347,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "sCI5DShkiDbT",
    "outputId": "92967fc5-5523-4262-955a-e46f8a6fe5b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STEPS = 150\n",
    "c=0\n",
    "for i in range(0,len(X_flipped),STEPS):\n",
    "  x, y = X_flipped[i], Y_flipped[i]\n",
    "  if len(np.unique(y)) == 1:\n",
    "    continue\n",
    "  x2d_marked = get_x2d_marked(x[:,:,0],y[:,:,0])\n",
    "  show_slices([x2d_marked,x[:,:,0]])\n",
    "  c+=1\n",
    "  if c==10:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mH4tH3fAiMW"
   },
   "source": [
    "## Join normal and flipped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WThfKwR4Ak8k"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ROW_SIZE = 224 # shapes of model inpput\n",
    "COL_SIZE = 176\n",
    "\n",
    "# need to allocate array before hand for efficient usage of memory\n",
    "X_doubled = np.zeros((37960*2,ROW_SIZE,COL_SIZE,1), dtype=np.float32)\n",
    "Y_doubled = np.zeros((37960*2,ROW_SIZE,COL_SIZE,1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1685858933629,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "1rWfhoI4BdP5",
    "outputId": "bcb27911-7392-45d9-b9bc-6d8e5d06dfb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75920, 224, 176, 1) (75920, 224, 176, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_doubled.shape, Y_doubled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4Jwc0owA4Bm"
   },
   "outputs": [],
   "source": [
    "X_doubled[0:37960] = X\n",
    "Y_doubled[0:37960] = Y\n",
    "\n",
    "X_doubled[37960:37960*2] = X_flipped\n",
    "Y_doubled[37960:37960*2] = Y_flipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1685859063899,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "O7L0Q5yMB8wn",
    "outputId": "12f32d57-1d99-43c3-aea7-0ee379c0e522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75920, 224, 176, 1) (75920, 224, 176, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_doubled.shape, Y_doubled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBezQ4AKDSeE"
   },
   "outputs": [],
   "source": [
    "X_output_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_ALL_DOUBLED_X.npy'\n",
    "Y_output_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_ALL_DOUBLED_Y.npy'\n",
    "\n",
    "save(X_output_path, X_doubled)\n",
    "save(Y_output_path, Y_doubled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bknw1StmCDhY"
   },
   "source": [
    "## Double check doubled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1zQBUWvqf9fTas7VqhLufU2SCjie27txE"
    },
    "executionInfo": {
     "elapsed": 8084,
     "status": "ok",
     "timestamp": 1685859389767,
     "user": {
      "displayName": "Alejandro M",
      "userId": "11111187776730726759"
     },
     "user_tz": 300
    },
    "id": "O_zuqb62CGlD",
    "outputId": "7f04a2a6-343f-43cf-c3aa-6a2b9b2d9497"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STEPS = 2438\n",
    "c=0\n",
    "for i in range(0,len(X_doubled),STEPS):\n",
    "  x, y = X_doubled[i], Y_doubled[i]\n",
    "  if len(np.unique(y)) == 1:\n",
    "    continue\n",
    "  x2d_marked = get_x2d_marked(x[:,:,0],y[:,:,0])\n",
    "  show_slices([x2d_marked,x[:,:,0]])\n",
    "  c+=1\n",
    "  if c==10:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4B0BhRTnxlxj",
    "9nUkyINb3zCR",
    "x3nnbYgj4qnZ",
    "Bknw1StmCDhY"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
