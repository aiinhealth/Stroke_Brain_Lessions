{"cells":[{"cell_type":"markdown","metadata":{"id":"v2XvrOWkyk9O"},"source":["First create a direct access to /datasets folder in your personal drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32175,"status":"ok","timestamp":1684684932975,"user":{"displayName":"Alejandro M","userId":"11111187776730726759"},"user_tz":300},"id":"eMNWO08O81RZ","outputId":"3c2f9eaf-c0f3-48fc-d661-534514db257d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Mount drive if needed\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"v8rt_QUUthFp"},"source":["\n","## Install dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36322,"status":"ok","timestamp":1684617559554,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"Bdm-G9y_1Wrw","outputId":"a7326027-fe6c-4c44-9943-ebf562e3424d"},"outputs":[],"source":["! pip install SimpleITK\n","! pip install antspyx"]},{"cell_type":"markdown","metadata":{"id":"4B0BhRTnxlxj"},"source":["\n","## Load images to current session"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7979,"status":"ok","timestamp":1684617590683,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"GhAcoJXWxqgK","outputId":"51d4abdf-e2c6-407a-c4b6-10ae91b99e4a"},"outputs":[],"source":["! mkdir -v data\n","! unzip \"/content/drive/MyDrive/integradora_fiec/datasets/NATIVE_FILTERED_MANUALLY.zip\" -d \"/data\""]},{"cell_type":"markdown","metadata":{"id":"9nUkyINb3zCR"},"source":["## Preprocessing steps functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4712,"status":"ok","timestamp":1684617606998,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"0rHZzByP5XeA","outputId":"01058e50-e5ce-4036-d881-e56a418cbe43"},"outputs":[{"name":"stdout","output_type":"stream","text":["AntsPy version = 0.3.8\n","SimpleITK version = 2.2.1\n"]}],"source":["%matplotlib inline\n","import os\n","import ants\n","import SimpleITK as sitk\n","\n","print(f'AntsPy version = {ants.__version__}')\n","print(f'SimpleITK version = {sitk.__version__}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"id8_NUqU4iHV"},"outputs":[],"source":["mni_T1_path = TEMPLATE_PATH = '/content/drive/MyDrive/integradora_fiec/datasets/templates/mni_icbm152_t1_tal_nlin_sym_09a.nii'\n","\n","def load_template_ants() -> ants.ANTsImage:\n","    \"\"\"\n","    Loads the template image using the ANTs library.\n","\n","    Returns:\n","        ants.ANTsImage: The loaded template image as an ANTsImage object.\n","    \"\"\"\n","    template_img_ants = ants.image_read(TEMPLATE_PATH)\n","    return template_img_ants\n","\n","def load_img_ants(path: str) -> ants.ANTsImage:\n","    \"\"\"\n","    Loads an image from the specified file path using the ANTs library.\n","\n","    Args:\n","        path (str): The file path of the image to be loaded.\n","\n","    Returns:\n","        ants.ANTsImage: The loaded image as an ANTsImage object.\n","    \"\"\"\n","    raw_img_ants = ants.image_read(path)\n","    return raw_img_ants\n","\n","def register_to_mni(img: ants.ANTsImage, mask: ants.ANTsImage) -> ants.ANTsImage:\n","    \"\"\"\n","    Registers an MRI image and its associated mask to the MNI space using ANTs library.\n","\n","    Args:\n","        img (ants.ANTsImage): The MRI image to be registered.\n","        mask (ants.ANTsImage): The mask associated with the MRI image.\n","\n","    Returns:\n","        ants.ANTsImage: The registered MRI image in MNI space.\n","        ants.ANTsImage: The registered mask in MNI space.\n","    \"\"\"\n","    template_img = load_template_ants()\n","    transformation = ants.registration(fixed=template_img, moving=img, type_of_transform='SyN')\n","\n","    img_registered = transformation['warpedmovout']\n","  \n","    mask_registered = ants.apply_transforms(fixed=template_img,moving=mask,transformlist=transformation['fwdtransforms'])\n","    return img_registered, mask_registered"]},{"cell_type":"markdown","metadata":{"id":"x3nnbYgj4qnZ"},"source":["## Register"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3r_861Ot4svp"},"outputs":[],"source":["from glob import glob\n","\n","xpaths = sorted(glob(f'/data/NATIVE_FILTERED_MANUALLY/train/*/*/*01.nii.gz') )\n","ypaths = sorted(glob(f'/data/NATIVE_FILTERED_MANUALLY/train/*/*/*_LesionSmooth.nii.gz'))\n","assert len(xpaths) == len(ypaths)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684617626409,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"2_L0ZjyRMYer","outputId":"9927f6bc-572e-499d-ab22-1477ef7dc05c"},"outputs":[],"source":["print(\"Number of samples:\", len(xpaths))\n","for input_path, target_path in zip(xpaths, ypaths):\n","    print(input_path[-35:], \"|\", target_path[-48:])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2823194,"status":"ok","timestamp":1684620459247,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"eCWkTx3B5vfL","outputId":"3a1e6484-32d9-4b5b-8b4a-2a8760d2c251"},"outputs":[],"source":["# Loop over the pairs of input and target file paths and perform registration to MNI space\n","for i,(xpath, ypath) in enumerate(zip(xpaths, ypaths)):\n","  folder = xpath[:-20]\n","  file_name = xpath[:-7][-13:]\n","  x_registered_path = folder + file_name + '_registered.nii.gz'\n","  y_registered_path = folder + file_name + '_LesionSmooth_registered.nii.gz'\n","\n","  x3d = load_img_ants(xpath)\n","  y3d = load_img_ants(ypath)\n","\n","  x3d_registered, y3d_registered = register_to_mni(img=x3d,mask=y3d)\n","\n","  print(i, x_registered_path)\n","  print(i, y_registered_path)\n","\n","  x3d_registered.to_file(x_registered_path)\n","  y3d_registered.to_file(y_registered_path)\n","\n","  #if i == 0 : break\n"]},{"cell_type":"markdown","metadata":{"id":"lmgC4KnjDc47"},"source":["## Bias Field Correction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RLqPRCMDgnv"},"outputs":[],"source":["xpaths = sorted(glob(f'/data/NATIVE_FILTERED_MANUALLY/train/*/*/*01_registered.nii.gz') )\n","ypaths = sorted(glob(f'/data/NATIVE_FILTERED_MANUALLY/train/*/*/*_LesionSmooth_registered.nii.gz'))\n","assert len(xpaths) == len(ypaths)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1684622758350,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"pL92X1T0DaUQ","outputId":"e2045b66-5d03-4d9f-8727-e060e9072823"},"outputs":[],"source":["print(\"Number of samples:\", len(xpaths))\n","for input_path, target_path in zip(xpaths, ypaths):\n","    print(input_path[-35:], \"|\", target_path[-48:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkXbZBb-Do1b"},"outputs":[],"source":["def bias_field_correction(img: sitk.Image) -> sitk.Image:\n","    \"\"\"\n","    Perform bias field correction on the input image using N4BiasFieldCorrection.\n","\n","    Args:\n","        img (sitk.Image): The input image to be bias corrected.\n","\n","    Returns:\n","        sitk.Image: The bias-corrected image.\n","    \"\"\"\n","    head_mask = sitk.RescaleIntensity(img, 0, 255)\n","    head_mask = sitk.LiThreshold(head_mask,0,1)\n","\n","    shrinkFactor = 4\n","    inputImage = img\n","    inputImage = sitk.Shrink( img, [ shrinkFactor ] * inputImage.GetDimension() )\n","    maskImage = sitk.Shrink( head_mask, [ shrinkFactor ] * inputImage.GetDimension() )\n","\n","    bias_corrector = sitk.N4BiasFieldCorrectionImageFilter()\n","    bias_corrector.Execute(inputImage, maskImage)\n","\n","    log_bias_field = bias_corrector.GetLogBiasFieldAsImage(img)\n","    result = img / sitk.Exp( log_bias_field ) # corrected img at full resolution\n","\n","    # output of division has 64 pixel type, we cast it to float32 to keep compatibility\n","    result = sitk.Cast(result, sitk.sitkFloat32)\n","    \n","    return result\n","\n","def load_img_sitk(path: str) -> sitk.Image:\n","    \"\"\"\n","    Load an image using SimpleITK (sitk) and return it.\n","\n","    Args:\n","        path (str): The path to the image file.\n","\n","    Returns:\n","        sitk.Image: The loaded image as a SimpleITK Image object.\n","    \"\"\"\n","    raw_img_sitk = sitk.ReadImage(path, sitk.sitkFloat32)\n","    return raw_img_sitk\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306882,"status":"ok","timestamp":1684623365527,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"Ye88JcOcEPIi","outputId":"1d829387-ac69-4edb-d08a-6f14e75de4a9"},"outputs":[],"source":["for i,(xpath, ypath) in enumerate(zip(xpaths, ypaths)):\n","  # Extract folder and file name information from the input and target file paths\n","  folder = xpath[:-20]\n","  file_name = xpath[:-7][-13:]\n","  # Create the output path for the bias field corrected image\n","  x_out_path = folder + file_name + '_BF.nii.gz'\n","\n","  x3d = load_img_sitk(xpath)\n","  x3d_bf_corrected = bias_field_correction(x3d)\n","\n","  sitk.WriteImage(x3d_bf_corrected, x_out_path)\n","  # Print the progress (index) and the output path of the bias field corrected image\n","  print(i, x_out_path)\n","\n","  #if i == 0 : break\n","\n"]},{"cell_type":"markdown","metadata":{"id":"f-m0hqWbFmyb"},"source":["## Prepare training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nn2SgDqQXTLr"},"outputs":[],"source":["xpaths = sorted(glob(f'/data/NATIVE_FILTERED_MANUALLY/train/*/*/*01_registered_BF.nii.gz') )\n","ypaths = sorted(glob(f'/data/NATIVE_FILTERED_MANUALLY/train/*/*/*_LesionSmooth_registered.nii.gz'))\n","assert len(xpaths) == len(ypaths)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1684623378122,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"SBlYCZJEXVir","outputId":"4cb5a127-2f21-435f-da32-1501874ce1b0"},"outputs":[],"source":["print(\"Number of samples:\", len(xpaths))\n","for input_path, target_path in zip(xpaths, ypaths):\n","    print(input_path[-35:], \"|\", target_path[-48:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8uEzKrrwFpHg"},"outputs":[],"source":["# load mni152 brain mask\n","TEMPLATE_BRAIN_MASK_PATH = '/content/drive/MyDrive/integradora_fiec/datasets/templates/mni_icbm152_t1_tal_nlin_sym_09a_mask.nii'\n","mni152_brain_mask = sitk.ReadImage(TEMPLATE_BRAIN_MASK_PATH, sitk.sitkFloat32)\n","mni152_T1 = sitk.ReadImage(TEMPLATE_PATH, sitk.sitkFloat32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RiCu-67XB7V"},"outputs":[],"source":["def preprocess_ximg(ximg: sitk.Image, flipped = False) -> np.ndarray:\n","  \"\"\"\n","    Preprocess the input image (ximg) using several SimpleITK image processing operations.\n","    \n","    Args:\n","        ximg (sitk.Image): The input image in SimpleITK format.\n","        flipped (bool, optional): Flag to determine whether to flip the image or not.\n","            Defaults to False.\n","\n","    Returns:\n","        np.ndarray: The preprocessed 3D numpy array representing the image.\n","\n","    \"\"\"\n","  x3d = sitk.HistogramMatching(ximg, mni152_T1)\n","  x3d = sitk.Multiply(x3d, mni152_brain_mask) # mask brain\n","  x3d = sitk.CurvatureAnisotropicDiffusion(x3d, conductanceParameter=1, numberOfIterations=1) # denoise a bit\n","  \n","  if flipped:\n","    x3d = sitk.Flip(x3d,(True, False, False))\n","  \n","  x3d = sitk.GetArrayFromImage(x3d)\n","  x3d = x3d[30:160,4:228,14:190] # crop to size -> (130, 224, 176)\n","  x3d = x3d / 255.0\n","  x3d = np.expand_dims(x3d,3) # add channel -> (130, 224, 176, 1)\n","  assert x3d.shape == (130,224,176,1)\n","  return x3d\n","\n","def preprocess_yimg(yimg: sitk.Image, flipped=False) -> np.ndarray:\n","  \"\"\"\n","    Preprocess the target image (yimg) for segmentation using SimpleITK image processing operations.\n","    \n","    Args:\n","        yimg (sitk.Image): The target image in SimpleITK format.\n","        flipped (bool, optional): Flag to determine whether to flip the image or not.\n","            Defaults to False.\n","\n","    Returns:\n","        np.ndarray: The preprocessed 3D numpy array representing the target segmentation.\n","\n","    \"\"\"\n","  y3d = yimg\n","\n","  if flipped:\n","    y3d = sitk.Flip(y3d,(True, False, False))\n","  \n","  y3d = sitk.GetArrayFromImage(y3d)\n","  y3d = y3d[30:160,4:228,14:190] # crop to size -> (130, 224, 176)\n","  y3d = y3d / 255.0\n","  y3d = np.expand_dims(y3d,3) # add channel -> (130, 224, 176, 1)\n","  assert x3d.shape == (130,224,176,1)\n","  return y3d\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132088,"status":"ok","timestamp":1684623530636,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"BrCYA5cgXPNr","outputId":"1ff1fe26-53f3-40f6-89a3-927441ce9109"},"outputs":[{"name":"stdout","output_type":"stream","text":["...................."]}],"source":["ROW_SIZE = 224 # Height of the model input\n","COL_SIZE = 176 # Width of the model input\n","\n","X = np.empty((0,ROW_SIZE,COL_SIZE,1), dtype=np.float32) # Placeholder for preprocessed input images\n","Y = np.empty((0,ROW_SIZE,COL_SIZE,1), dtype=np.float32) # Placeholder for preprocessed label images\n","\n","for i,(xpath, ypath) in enumerate(zip(xpaths, ypaths)):\n","\n","    ximg        =   sitk.ReadImage(xpath, sitk.sitkFloat32)\n","    x3d         =  preprocess_ximg(ximg) \n","    flipped_x3d =  preprocess_ximg(ximg, flipped=True)\n","\n","    yimg        =   sitk.ReadImage(ypath, sitk.sitkFloat32)\n","    y3d         =  preprocess_yimg(yimg) \n","    flipped_y3d =  preprocess_yimg(yimg, flipped=True)\n","\n","    # Concatenate the preprocessed images (original and flipped) along the first axis (number of samples)\n","    x3d = np.concatenate((x3d, flipped_x3d), axis=0)\n","    y3d = np.concatenate((y3d, flipped_y3d), axis=0)\n","\n","    # Ensure the shapes of the concatenated arrays are as expected\n","    assert x3d.shape  == (260,224,176, 1)\n","    assert y3d.shape  == (260,224,176, 1)\n","\n","    X = np.concatenate((X, x3d), axis=0)\n","    Y = np.concatenate((Y, y3d), axis=0)\n","\n","    print('.', end='')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1684623536305,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"hDweE5HsXc2z","outputId":"eea054e4-1c0b-4206-cc47-25fa6ddca341"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5200, 224, 176, 1) (5200, 224, 176, 1)\n"]}],"source":["print(X.shape, Y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1684623678692,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"WmpXKtSKZNQI","outputId":"64d275b4-aefe-4abf-ade0-ffdf169dae9d"},"outputs":[{"data":{"text/plain":["(5200, 224, 176)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["X[:,:,:,0].shape"]},{"cell_type":"markdown","metadata":{"id":"ltHhwU2sY0TD"},"source":["## Double check slices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCC2IlRXbUpL"},"outputs":[],"source":["def get_x2d_marked(x2d,y2d):\n","  \"\"\"\n","    Mark the input 2D image (x2d) using the contours of the label image (y2d).\n","\n","    Args:\n","        x2d (np.ndarray): The 2D input image.\n","        y2d (np.ndarray): The 2D label image.\n","\n","    Returns:\n","        np.ndarray: The marked version of the input image.\n","    \"\"\"\n","  dilation_level = 4\n","  m = (y2d).astype('uint8')\n","  m = sitk.GetImageFromArray(m)\n","  m = sitk.BinaryDilate(m,(dilation_level,1,1))\n","  m = sitk.BinaryContour(m)\n","\n","  x2d_marked = sitk.GetImageFromArray(x2d)\n","  x2d_marked = sitk.MaskNegated(x2d_marked, sitk.Cast(m,sitk.sitkFloat32))\n","  x2d_marked = sitk.GetArrayFromImage(x2d_marked)\n","  return x2d_marked\n","\n","def show_slices(slices: list[np.ndarray], cmap: str ='gray'):\n","  \"\"\"\n","    Display a list of image slices (2D arrays) as subplots in a single figure.\n","\n","    Args:\n","        slices (list[np.ndarray]): A list of 2D numpy arrays representing image slices.\n","        cmap (str, optional): The colormap to be used for visualization. Defaults to 'gray'.\n","    \"\"\"\n","  fig, axes = plt.subplots(len(slices), 1, figsize=(15,15))\n","  for i, slice in enumerate(slices):\n","    axes[i].imshow(slice, cmap=cmap)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1JBRG54fzeib_ox4P_O5BrYzHKyWzK4qv"},"executionInfo":{"elapsed":8971,"status":"ok","timestamp":1684624259410,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"eZaRB9ZobXN2","outputId":"98f104b6-d690-4f29-c072-4ec9c595fd48"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["STEPS = 150\n","c=0\n","for i in range(0,len(X),STEPS):\n","  x, y = X[i], Y[i]\n","  if len(np.unique(y)) == 1:\n","    continue\n","  x2d_marked = get_x2d_marked(x[:,:,0],y[:,:,0])\n","  show_slices([x2d_marked,x[:,:,0]])\n","  c+=1\n","  if c==10:\n","    break"]},{"cell_type":"markdown","metadata":{"id":"yFrpmprabxsB"},"source":["## Save training dataset as npy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAPpbgVZbreV"},"outputs":[],"source":["from numpy import save\n","# contains data processed from 20 native ATLAS imgs trough: register to mni, bias field, histogram matching, brain extraction, denoise\n","X_output_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_X.npy'\n","Y_output_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_Y.npy'\n","\n","\n","save(X_output_path, X)\n","save(Y_output_path, Y)"]},{"cell_type":"markdown","metadata":{"id":"jrrVAd_tdnYB"},"source":["## Load train set [JUMP HERE IF DATA AVAILABLE]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SkMS-YnjdpD2"},"outputs":[],"source":["from numpy import load\n","X_input_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper lesions extended/dataset_clinet_input_processed_X.npy'\n","Y_input_path = '/content/drive/MyDrive/integradora_fiec/datasets/paper_lesions extended/dataset_clinet_input_processed_Y.npy'\n","\n","X = load(X_input_path)\n","Y = load(Y_input_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":187,"status":"ok","timestamp":1684625616949,"user":{"displayName":"Roberto Alejandro Mena Ramirez","userId":"17762559014980159599"},"user_tz":300},"id":"iMQcUwCQd6mi","outputId":"366562a2-8633-4060-c463-f0ba598b4b8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5200, 224, 176, 1) (5200, 224, 176, 1)\n"]}],"source":["print(X.shape, Y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1816,"status":"ok","timestamp":1684685371862,"user":{"displayName":"Alejandro M","userId":"11111187776730726759"},"user_tz":300},"id":"HYCPtTeJf9qC","outputId":"1d98ef2b-99d0-4e5b-8e5a-bffa69298932"},"outputs":[{"name":"stdout","output_type":"stream","text":["(4160, 224, 176, 1) (4160, 224, 176, 1)\n","(1040, 224, 176, 1) (1040, 224, 176, 1)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)\n","print(X_train.shape, y_train.shape)\n","print(X_valid.shape, y_valid.shape)"]},{"cell_type":"markdown","metadata":{"id":"ppzbluM7fFF7"},"source":["## Define Train Model (CLCI net)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWEZusUufI-b"},"outputs":[],"source":["from keras import *\n","from keras.layers import *\n","import tensorflow as tf\n","kernel_regularizer = regularizers.l2(1e-5)\n","bias_regularizer = regularizers.l2(1e-5)\n","kernel_regularizer = None\n","bias_regularizer = None\n","\n","def conv_lstm(input1, input2, channel=256):\n","    lstm_input1 = Reshape((1, input1.shape.as_list()[1], input1.shape.as_list()[2], input1.shape.as_list()[3]))(input1)\n","    lstm_input2 = Reshape((1, input2.shape.as_list()[1], input2.shape.as_list()[2], input1.shape.as_list()[3]))(input2)\n","\n","    lstm_input = custom_concat(axis=1)([lstm_input1, lstm_input2])\n","    x = ConvLSTM2D(channel, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=kernel_regularizer)(lstm_input)\n","    return x\n","\n","def conv_2(inputs, filter_num, kernel_size=(3,3), strides=(1,1), kernel_initializer='glorot_uniform', kernel_regularizer = kernel_regularizer):\n","    conv_ = Conv2D(filter_num, kernel_size=kernel_size, strides=strides, padding='same', kernel_initializer=kernel_initializer, kernel_regularizer = kernel_regularizer)(inputs)\n","    conv_ = BatchNormalization()(conv_)\n","    conv_ = Activation('relu')(conv_)\n","    conv_ = Conv2D(filter_num, kernel_size=kernel_size, strides=strides, padding='same', kernel_initializer=kernel_initializer, kernel_regularizer = kernel_regularizer)(conv_)\n","    conv_ = BatchNormalization()(conv_)\n","    conv_ = Activation('relu')(conv_)   \n","    return conv_\n","\n","def conv_2_init(inputs, filter_num, kernel_size=(3,3), strides=(1,1)):\n","    return conv_2(inputs, filter_num, kernel_size=kernel_size, strides=strides, kernel_initializer='he_normal', kernel_regularizer = kernel_regularizer) \n","\n","def conv_2_init_regularization(inputs, filter_num, kernel_size=(3,3), strides=(1,1)):\n","    return conv_2(inputs, filter_num, kernel_size=kernel_size, strides=strides, kernel_initializer='he_normal', kernel_regularizer = regularizers.l2(5e-4)) \n","\n","def conv_1(inputs, filter_num, kernel_size=(3,3), strides=(1,1), kernel_initializer='glorot_uniform', kernel_regularizer = kernel_regularizer):\n","    conv_ = Conv2D(filter_num, kernel_size=kernel_size, strides=strides, padding='same', kernel_initializer=kernel_initializer, kernel_regularizer = kernel_regularizer)(inputs)\n","    conv_ = BatchNormalization()(conv_)\n","    conv_ = Activation('relu')(conv_)\n","    return conv_\n","\n","def conv_1_init(inputs, filter_num, kernel_size=(3,3), strides=(1,1)):\n","    return conv_1(inputs, filter_num, kernel_size=kernel_size, strides=strides, kernel_initializer='he_normal', kernel_regularizer = kernel_regularizer) \n","\n","def conv_1_init_regularization(inputs, filter_num, kernel_size=(3,3), strides=(1,1)):\n","    return conv_1(inputs, filter_num, kernel_size=kernel_size, strides=strides, kernel_initializer='he_normal', kernel_regularizer = regularizers.l2(5e-4))\n","\n","def dilate_conv(inputs, filter_num, dilation_rate):\n","    conv_ = Conv2D(filter_num, kernel_size=(3,3), dilation_rate=dilation_rate, padding='same', kernel_initializer='he_normal', kernel_regularizer = kernel_regularizer)(inputs)\n","    conv_ = BatchNormalization()(conv_)\n","    conv_ = Activation('relu')(conv_)\n","    return conv_\n","\n","class custom_concat(Layer):\n","\n","    def __init__(self, axis=-1, **kwargs):\n","        super(custom_concat, self).__init__(**kwargs)\n","        self.axis = axis\n","\n","    def build(self, input_shape):\n","        # Create a trainable weight variable for this layer.\n","        self.built = True\n","        super(custom_concat, self).build(input_shape)  # Be sure to call this somewhere!\n","\n","    def call(self, x):\n","        self.res = tf.concat(x, self.axis)\n","\n","        return self.res\n","\n","    def compute_output_shape(self, input_shape):\n","        # return (input_shape[0][0],)+(len(input_shape),)+input_shape[0][2:]\n","        # print((input_shape[0][0],)+(len(input_shape),)+input_shape[0][2:])\n","        input_shapes = input_shape\n","        output_shape = list(input_shapes[0])\n","\n","        for shape in input_shapes[1:]:\n","            if output_shape[self.axis] is None or shape[self.axis] is None:\n","                output_shape[self.axis] = None\n","                break\n","            output_shape[self.axis] += shape[self.axis]\n","\n","        return tuple(output_shape)\n","\n","\n","class BilinearUpsampling(Layer):\n","    def __init__(self, upsampling=(2, 2), **kwargs):\n","        super(BilinearUpsampling, self).__init__(**kwargs)       \n","        self.upsampling = upsampling\n","        \n","    def compute_output_shape(self, input_shape):\n","        height = self.upsampling[0] * \\\n","                 input_shape[1] if input_shape[1] is not None else None\n","        width = self.upsampling[1] * \\\n","                input_shape[2] if input_shape[2] is not None else None\n","        return (input_shape[0],\n","                height,\n","                width,\n","                input_shape[3])\n","\n","    def call(self, inputs):\n","        #return tf.image.resize_bilinear(inputs, (int(inputs.shape[1] * self.upsampling[0]),\n","        #                                           int(inputs.shape[2] * self.upsampling[1])))\n","        return tf.image.resize(inputs, (int(inputs.shape[1] * self.upsampling[0]),\n","                                                   int(inputs.shape[2] * self.upsampling[1])))\n","\n","\n","\n","def concat_pool(conv, pool, filter_num, strides=(2, 2)):\n","    conv_downsample = Conv2D(filter_num, (3, 3), strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=kernel_regularizer)(conv)\n","    conv_downsample = BatchNormalization()(conv_downsample)\n","    conv_downsample = Activation('relu')(conv_downsample)\n","    concat_pool_ = Concatenate()([conv_downsample, pool])\n","    return concat_pool_\n","######################################\n","from keras.optimizers import Adam\n","import keras.backend as K\n","#from custom_layer import *\n","\n","\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + 1) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f) + 1)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return 1. - dice_coef(y_true, y_pred)\n","\n","def CLCI_Net(input_shape=(224, 176, 1), num_class=1):\n","    # The row and col of input should be resized or cropped to an integer multiple of 16.\n","    inputs = Input(shape=input_shape)\n","\n","    conv1 = conv_2_init(inputs, 32)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    concat_pool11 = concat_pool(conv1, pool1, 32, strides=(2, 2))\n","    fusion1 = conv_1_init(concat_pool11, 64 * 4, kernel_size=(1, 1))\n","\n","    conv2 = conv_2_init(fusion1, 64)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    concat_pool12 = concat_pool(conv1, pool2, 64, strides=(4, 4))\n","    concat_pool22 = concat_pool(conv2, concat_pool12, 64, strides=(2, 2))\n","    fusion2 = conv_1_init(concat_pool22, 128 * 4, kernel_size=(1, 1))\n","\n","    conv3 = conv_2_init(fusion2, 128)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    concat_pool13 = concat_pool(conv1, pool3, 128, strides=(8, 8))\n","    concat_pool23 = concat_pool(conv2, concat_pool13, 128, strides=(4, 4))\n","    concat_pool33 = concat_pool(conv3, concat_pool23, 128, strides=(2, 2))\n","    fusion3 = conv_1_init(concat_pool33, 256 * 4, kernel_size=(1, 1))\n","\n","    conv4 = conv_2_init(fusion3, 256)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","    concat_pool14 = concat_pool(conv1, pool4, 256, strides=(16, 16))\n","    concat_pool24 = concat_pool(conv2, concat_pool14, 256, strides=(8, 8))\n","    concat_pool34 = concat_pool(conv3, concat_pool24, 256, strides=(4, 4))\n","    concat_pool44 = concat_pool(conv4, concat_pool34, 256, strides=(2, 2))\n","    fusion4 = conv_1_init(concat_pool44, 512 * 4, kernel_size=(1, 1))\n","\n","    conv5 = conv_2_init(fusion4, 512)\n","    conv5 = Dropout(0.5)(conv5)\n","\n","    clf_aspp = CLF_ASPP(conv5, conv1, conv2, conv3, conv4, input_shape)\n","\n","    up_conv1 = UpSampling2D(size=(2, 2))(clf_aspp)\n","    up_conv1 = conv_1_init(up_conv1, 256, kernel_size=(2, 2))\n","    skip_conv4 = conv_1_init(conv4, 256, kernel_size=(1, 1))\n","    context_inference1 = conv_lstm(up_conv1, skip_conv4, channel=256)\n","    conv6 = conv_2_init(context_inference1, 256)\n","\n","    up_conv2 = UpSampling2D(size=(2, 2))(conv6)\n","    up_conv2 = conv_1_init(up_conv2, 128, kernel_size=(2, 2))\n","    skip_conv3 = conv_1_init(conv3, 128, kernel_size=(1, 1))\n","    context_inference2 = conv_lstm(up_conv2, skip_conv3, channel=128)\n","    conv7 = conv_2_init(context_inference2, 128)\n","\n","    up_conv3 = UpSampling2D(size=(2, 2))(conv7)\n","    up_conv3 = conv_1_init(up_conv3, 64, kernel_size=(2, 2))\n","    skip_conv2 = conv_1_init(conv2, 64, kernel_size=(1, 1))\n","    context_inference3 = conv_lstm(up_conv3, skip_conv2, channel=64)\n","    conv8 = conv_2_init(context_inference3, 64)\n","\n","    up_conv4 = UpSampling2D(size=(2, 2))(conv8)\n","    up_conv4 = conv_1_init(up_conv4, 32, kernel_size=(2, 2))\n","    skip_conv1 = conv_1_init(conv1, 32, kernel_size=(1, 1))\n","    context_inference4 = conv_lstm(up_conv4, skip_conv1, channel=32)\n","    conv9 = conv_2_init(context_inference4, 32)\n","\n","\n","    if num_class == 1:\n","        conv10 = Conv2D(num_class, (1, 1), activation='sigmoid')(conv9)\n","    else:\n","        conv10 = Conv2D(num_class, (1, 1), activation='softmax')(conv9)\n","\n","    model = Model(inputs=inputs, outputs=conv10)\n","\n","    return model\n","\n","\n","def CLF_ASPP(conv5, conv1, conv2, conv3, conv4, input_shape):\n","\n","    b0 = conv_1_init(conv5, 256, (1, 1))\n","    b1 = dilate_conv(conv5, 256, dilation_rate=(2, 2))\n","    b2 = dilate_conv(conv5, 256, dilation_rate=(4, 4))\n","    b3 = dilate_conv(conv5, 256, dilation_rate=(6, 6))\n","\n","    out_shape0 = input_shape[0] // pow(2, 4)\n","    out_shape1 = input_shape[1] // pow(2, 4)\n","    b4 = AveragePooling2D(pool_size=(out_shape0, out_shape1))(conv5)\n","    b4 = conv_1_init(b4, 256, (1, 1))\n","    b4 = BilinearUpsampling((out_shape0, out_shape1))(b4)\n","\n","    clf1 = conv_1_init(conv1, 256, strides=(16, 16))\n","    clf2 = conv_1_init(conv2, 256, strides=(8, 8))\n","    clf3 = conv_1_init(conv3, 256, strides=(4, 4))\n","    clf4 = conv_1_init(conv4, 256, strides=(2, 2))\n","\n","    outs = Concatenate()([clf1, clf2, clf3, clf4, b0, b1, b2, b3, b4])\n","\n","    outs = conv_1_init(outs, 256 * 4, (1, 1))\n","    outs = Dropout(0.5)(outs)\n","\n","    return outs"]},{"cell_type":"markdown","metadata":{"id":"uxHOyn9MfWnk"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6572,"status":"ok","timestamp":1684685395321,"user":{"displayName":"Alejandro M","userId":"11111187776730726759"},"user_tz":300},"id":"2Z3BHZMLfYDM","outputId":"e7e6386e-f466-4050-f12b-cc58cf3a76b5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}],"source":["from keras.metrics import  Recall, Precision\n","# https://stats.stackexchange.com/questions/323154/precision-vs-recall-acceptable-limits\n","# https://www.kdnuggets.com/2016/12/4-reasons-machine-learning-model-wrong.html#:~:text=Precision%20is%20a%20measure%20of,positive%20class%20are%20actually%20true.&text=Hence%2C%20a%20situation%20of%20Low,positive%20values%20are%20never%20predicted.\n","# Pre and Post processing # https://github.com/nikhilroxtomar/UNet-Segmentation-in-Keras-TensorFlow/blob/master/unet-segmentation.ipynb\n","model = CLCI_Net()\n","#model.summary()\n","model.compile(optimizer=Adam(lr=1e-4), loss=dice_coef_loss, metrics=[dice_coef,'acc',Recall(), Precision()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"07RINufyfPjc"},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","\n","checkpoint_filepath = '/content/drive/MyDrive/integradora_fiec/modelos/clcinet-native-filtered-v2-{epoch:03d}-{dice_coef:03f}-{val_dice_coef:03f}.h5'\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='val_dice_coef',\n","    mode='max',\n","    save_best_only=True)\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.2, patience=2, min_lr=2e-6)\n","\n","callbacks = [\n","    model_checkpoint_callback,\n","    reduce_lr\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MyoJ7LoYf32M","outputId":"9c73b839-ed07-441c-c4a1-a70992087b98"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/60\n","520/520 [==============================] - 466s 841ms/step - loss: 0.7126 - dice_coef: 0.2874 - acc: 0.9772 - recall: 0.5078 - precision: 0.1813 - val_loss: 0.8592 - val_dice_coef: 0.1408 - val_acc: 0.9379 - val_recall: 0.8104 - val_precision: 0.1016 - lr: 1.0000e-04\n","Epoch 2/60\n","520/520 [==============================] - 434s 835ms/step - loss: 0.5154 - dice_coef: 0.4846 - acc: 0.9928 - recall: 0.5407 - precision: 0.6043 - val_loss: 0.4455 - val_dice_coef: 0.5545 - val_acc: 0.9950 - val_recall: 0.6466 - val_precision: 0.8302 - lr: 1.0000e-04\n","Epoch 3/60\n","520/520 [==============================] - 433s 832ms/step - loss: 0.3959 - dice_coef: 0.6041 - acc: 0.9946 - recall: 0.5707 - precision: 0.7978 - val_loss: 0.4661 - val_dice_coef: 0.5339 - val_acc: 0.9937 - val_recall: 0.6613 - val_precision: 0.6920 - lr: 1.0000e-04\n","Epoch 4/60\n","520/520 [==============================] - 422s 811ms/step - loss: 0.2889 - dice_coef: 0.7111 - acc: 0.9956 - recall: 0.6220 - precision: 0.9069 - val_loss: 0.3178 - val_dice_coef: 0.6822 - val_acc: 0.9958 - val_recall: 0.6617 - val_precision: 0.9224 - lr: 2.0000e-05\n","Epoch 5/60\n","520/520 [==============================] - 422s 811ms/step - loss: 0.2539 - dice_coef: 0.7461 - acc: 0.9959 - recall: 0.6480 - precision: 0.9283 - val_loss: 0.2708 - val_dice_coef: 0.7292 - val_acc: 0.9960 - val_recall: 0.7109 - val_precision: 0.9202 - lr: 2.0000e-05\n","Epoch 6/60\n","520/520 [==============================] - 433s 834ms/step - loss: 0.2370 - dice_coef: 0.7630 - acc: 0.9960 - recall: 0.6633 - precision: 0.9383 - val_loss: 0.2661 - val_dice_coef: 0.7339 - val_acc: 0.9960 - val_recall: 0.7058 - val_precision: 0.9170 - lr: 4.0000e-06\n","Epoch 7/60\n","520/520 [==============================] - 434s 834ms/step - loss: 0.2249 - dice_coef: 0.7751 - acc: 0.9960 - recall: 0.6590 - precision: 0.9430 - val_loss: 0.2633 - val_dice_coef: 0.7367 - val_acc: 0.9961 - val_recall: 0.6914 - val_precision: 0.9398 - lr: 4.0000e-06\n","Epoch 8/60\n","520/520 [==============================] - 434s 834ms/step - loss: 0.2335 - dice_coef: 0.7665 - acc: 0.9960 - recall: 0.6643 - precision: 0.9406 - val_loss: 0.2609 - val_dice_coef: 0.7391 - val_acc: 0.9961 - val_recall: 0.6776 - val_precision: 0.9481 - lr: 2.0000e-06\n","Epoch 9/60\n","520/520 [==============================] - 434s 834ms/step - loss: 0.2197 - dice_coef: 0.7803 - acc: 0.9961 - recall: 0.6640 - precision: 0.9476 - val_loss: 0.2556 - val_dice_coef: 0.7444 - val_acc: 0.9961 - val_recall: 0.6881 - val_precision: 0.9429 - lr: 2.0000e-06\n","Epoch 10/60\n","520/520 [==============================] - 434s 835ms/step - loss: 0.2092 - dice_coef: 0.7908 - acc: 0.9961 - recall: 0.6700 - precision: 0.9463 - val_loss: 0.2518 - val_dice_coef: 0.7482 - val_acc: 0.9961 - val_recall: 0.6965 - val_precision: 0.9375 - lr: 2.0000e-06\n","Epoch 11/60\n","520/520 [==============================] - 422s 811ms/step - loss: 0.2101 - dice_coef: 0.7899 - acc: 0.9961 - recall: 0.6722 - precision: 0.9478 - val_loss: 0.2494 - val_dice_coef: 0.7506 - val_acc: 0.9961 - val_recall: 0.6945 - val_precision: 0.9428 - lr: 2.0000e-06\n","Epoch 12/60\n","520/520 [==============================] - 433s 832ms/step - loss: 0.2178 - dice_coef: 0.7822 - acc: 0.9961 - recall: 0.6696 - precision: 0.9486 - val_loss: 0.2512 - val_dice_coef: 0.7488 - val_acc: 0.9961 - val_recall: 0.7002 - val_precision: 0.9371 - lr: 2.0000e-06\n","Epoch 13/60\n","520/520 [==============================] - 433s 833ms/step - loss: 0.2038 - dice_coef: 0.7962 - acc: 0.9961 - recall: 0.6766 - precision: 0.9488 - val_loss: 0.2433 - val_dice_coef: 0.7567 - val_acc: 0.9961 - val_recall: 0.7045 - val_precision: 0.9400 - lr: 2.0000e-06\n","Epoch 14/60\n","520/520 [==============================] - 433s 833ms/step - loss: 0.1984 - dice_coef: 0.8016 - acc: 0.9962 - recall: 0.6767 - precision: 0.9513 - val_loss: 0.2398 - val_dice_coef: 0.7602 - val_acc: 0.9962 - val_recall: 0.7031 - val_precision: 0.9416 - lr: 2.0000e-06\n","Epoch 15/60\n","520/520 [==============================] - 433s 832ms/step - loss: 0.1943 - dice_coef: 0.8057 - acc: 0.9962 - recall: 0.6794 - precision: 0.9494 - val_loss: 0.2403 - val_dice_coef: 0.7597 - val_acc: 0.9962 - val_recall: 0.6982 - val_precision: 0.9439 - lr: 2.0000e-06\n","Epoch 16/60\n","520/520 [==============================] - 434s 834ms/step - loss: 0.1902 - dice_coef: 0.8098 - acc: 0.9962 - recall: 0.6808 - precision: 0.9527 - val_loss: 0.2361 - val_dice_coef: 0.7639 - val_acc: 0.9962 - val_recall: 0.7105 - val_precision: 0.9389 - lr: 2.0000e-06\n","Epoch 17/60\n","520/520 [==============================] - 421s 810ms/step - loss: 0.1907 - dice_coef: 0.8093 - acc: 0.9962 - recall: 0.6809 - precision: 0.9550 - val_loss: 0.2372 - val_dice_coef: 0.7628 - val_acc: 0.9962 - val_recall: 0.7059 - val_precision: 0.9436 - lr: 2.0000e-06\n","Epoch 18/60\n","520/520 [==============================] - 422s 811ms/step - loss: 0.1853 - dice_coef: 0.8147 - acc: 0.9962 - recall: 0.6796 - precision: 0.9552 - val_loss: 0.2346 - val_dice_coef: 0.7654 - val_acc: 0.9962 - val_recall: 0.7021 - val_precision: 0.9463 - lr: 2.0000e-06\n","Epoch 19/60\n","520/520 [==============================] - 422s 811ms/step - loss: 0.1982 - dice_coef: 0.8018 - acc: 0.9962 - recall: 0.6857 - precision: 0.9532 - val_loss: 0.2313 - val_dice_coef: 0.7687 - val_acc: 0.9962 - val_recall: 0.7075 - val_precision: 0.9421 - lr: 2.0000e-06\n","Epoch 20/60\n","520/520 [==============================] - 421s 810ms/step - loss: 0.1930 - dice_coef: 0.8070 - acc: 0.9962 - recall: 0.6802 - precision: 0.9551 - val_loss: 0.2283 - val_dice_coef: 0.7717 - val_acc: 0.9962 - val_recall: 0.7187 - val_precision: 0.9410 - lr: 2.0000e-06\n","Epoch 21/60\n","520/520 [==============================] - 421s 809ms/step - loss: 0.1781 - dice_coef: 0.8219 - acc: 0.9962 - recall: 0.6894 - precision: 0.9557 - val_loss: 0.2306 - val_dice_coef: 0.7694 - val_acc: 0.9962 - val_recall: 0.7022 - val_precision: 0.9439 - lr: 2.0000e-06\n","Epoch 22/60\n","520/520 [==============================] - 421s 810ms/step - loss: 0.1999 - dice_coef: 0.8001 - acc: 0.9962 - recall: 0.6835 - precision: 0.9578 - val_loss: 0.2254 - val_dice_coef: 0.7746 - val_acc: 0.9962 - val_recall: 0.7153 - val_precision: 0.9450 - lr: 2.0000e-06\n","Epoch 23/60\n","520/520 [==============================] - 421s 811ms/step - loss: 0.1715 - dice_coef: 0.8285 - acc: 0.9963 - recall: 0.6907 - precision: 0.9585 - val_loss: 0.2242 - val_dice_coef: 0.7758 - val_acc: 0.9962 - val_recall: 0.7145 - val_precision: 0.9450 - lr: 2.0000e-06\n","Epoch 24/60\n","520/520 [==============================] - 422s 811ms/step - loss: 0.1831 - dice_coef: 0.8169 - acc: 0.9963 - recall: 0.6896 - precision: 0.9587 - val_loss: 0.2214 - val_dice_coef: 0.7786 - val_acc: 0.9962 - val_recall: 0.7334 - val_precision: 0.9335 - lr: 2.0000e-06\n","Epoch 25/60\n","520/520 [==============================] - 433s 834ms/step - loss: 0.1836 - dice_coef: 0.8164 - acc: 0.9963 - recall: 0.6957 - precision: 0.9593 - val_loss: 0.2198 - val_dice_coef: 0.7802 - val_acc: 0.9963 - val_recall: 0.7243 - val_precision: 0.9432 - lr: 2.0000e-06\n","Epoch 26/60\n","520/520 [==============================] - 434s 835ms/step - loss: 0.1778 - dice_coef: 0.8222 - acc: 0.9963 - recall: 0.6951 - precision: 0.9594 - val_loss: 0.2183 - val_dice_coef: 0.7817 - val_acc: 0.9963 - val_recall: 0.7197 - val_precision: 0.9450 - lr: 2.0000e-06\n","Epoch 27/60\n","520/520 [==============================] - 433s 832ms/step - loss: 0.1960 - dice_coef: 0.8040 - acc: 0.9963 - recall: 0.6958 - precision: 0.9598 - val_loss: 0.2207 - val_dice_coef: 0.7793 - val_acc: 0.9963 - val_recall: 0.7126 - val_precision: 0.9490 - lr: 2.0000e-06\n","Epoch 28/60\n","520/520 [==============================] - 421s 811ms/step - loss: 0.1779 - dice_coef: 0.8221 - acc: 0.9963 - recall: 0.6952 - precision: 0.9609 - val_loss: 0.2157 - val_dice_coef: 0.7843 - val_acc: 0.9963 - val_recall: 0.7254 - val_precision: 0.9406 - lr: 2.0000e-06\n","Epoch 29/60\n","520/520 [==============================] - 433s 834ms/step - loss: 0.1782 - dice_coef: 0.8218 - acc: 0.9963 - recall: 0.6991 - precision: 0.9614 - val_loss: 0.2124 - val_dice_coef: 0.7876 - val_acc: 0.9963 - val_recall: 0.7227 - val_precision: 0.9447 - lr: 2.0000e-06\n","Epoch 30/60\n","520/520 [==============================] - 433s 832ms/step - loss: 0.1675 - dice_coef: 0.8325 - acc: 0.9963 - recall: 0.6969 - precision: 0.9625 - val_loss: 0.2152 - val_dice_coef: 0.7848 - val_acc: 0.9963 - val_recall: 0.7054 - val_precision: 0.9557 - lr: 2.0000e-06\n","Epoch 31/60\n","276/520 [==============>...............] - ETA: 3:03 - loss: 0.1739 - dice_coef: 0.8261 - acc: 0.9965 - recall: 0.7067 - precision: 0.9641"]}],"source":["history = model.fit(\n","      X_train, y_train,\n","      batch_size=8,\n","      epochs=60,\n","      verbose=1,\n","      callbacks=callbacks,\n","      validation_data=(X_valid,y_valid))"]},{"cell_type":"markdown","metadata":{"id":"wW2znXbQhyQf"},"source":["retrain after timeout..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AHm8WG9Qh1vz"},"outputs":[],"source":["model.load_weights(\"/content/drive/MyDrive/integradora_fiec/modelos/clcinet-native-filtered-v2-029-0.821825-0.787639.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eb8GWyV2ihQm","outputId":"87bca2da-d826-4982-a5f4-f47222012854"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/31\n","520/520 [==============================] - 448s 806ms/step - loss: 0.2782 - dice_coef: 0.7218 - acc: 0.9955 - recall: 0.6107 - precision: 0.9064 - val_loss: 0.2864 - val_dice_coef: 0.7136 - val_acc: 0.9959 - val_recall: 0.6375 - val_precision: 0.9359 - lr: 1.0000e-04\n","Epoch 2/31\n","520/520 [==============================] - 423s 814ms/step - loss: 0.2649 - dice_coef: 0.7351 - acc: 0.9956 - recall: 0.6210 - precision: 0.9018 - val_loss: 0.4926 - val_dice_coef: 0.5074 - val_acc: 0.9921 - val_recall: 0.6380 - val_precision: 0.5587 - lr: 1.0000e-04\n","Epoch 3/31\n","520/520 [==============================] - 424s 815ms/step - loss: 0.2423 - dice_coef: 0.7577 - acc: 0.9957 - recall: 0.6460 - precision: 0.9063 - val_loss: 0.2778 - val_dice_coef: 0.7222 - val_acc: 0.9959 - val_recall: 0.5989 - val_precision: 0.9602 - lr: 1.0000e-04\n","Epoch 4/31\n","520/520 [==============================] - 423s 814ms/step - loss: 0.2209 - dice_coef: 0.7791 - acc: 0.9959 - recall: 0.6442 - precision: 0.9304 - val_loss: 0.3489 - val_dice_coef: 0.6511 - val_acc: 0.9953 - val_recall: 0.6258 - val_precision: 0.8550 - lr: 1.0000e-04\n","Epoch 5/31\n","520/520 [==============================] - 412s 792ms/step - loss: 0.1940 - dice_coef: 0.8060 - acc: 0.9961 - recall: 0.6710 - precision: 0.9501 - val_loss: 0.2156 - val_dice_coef: 0.7844 - val_acc: 0.9962 - val_recall: 0.7310 - val_precision: 0.9268 - lr: 2.0000e-05\n","Epoch 6/31\n","520/520 [==============================] - 413s 794ms/step - loss: 0.1592 - dice_coef: 0.8408 - acc: 0.9963 - recall: 0.6871 - precision: 0.9609 - val_loss: 0.1941 - val_dice_coef: 0.8059 - val_acc: 0.9963 - val_recall: 0.7206 - val_precision: 0.9480 - lr: 2.0000e-05\n","Epoch 7/31\n","520/520 [==============================] - 425s 818ms/step - loss: 0.1521 - dice_coef: 0.8479 - acc: 0.9963 - recall: 0.7008 - precision: 0.9622 - val_loss: 0.1868 - val_dice_coef: 0.8132 - val_acc: 0.9963 - val_recall: 0.7068 - val_precision: 0.9592 - lr: 4.0000e-06\n","Epoch 8/31\n","520/520 [==============================] - 424s 816ms/step - loss: 0.1488 - dice_coef: 0.8512 - acc: 0.9964 - recall: 0.6979 - precision: 0.9674 - val_loss: 0.1818 - val_dice_coef: 0.8182 - val_acc: 0.9963 - val_recall: 0.7174 - val_precision: 0.9560 - lr: 4.0000e-06\n","Epoch 9/31\n","520/520 [==============================] - 423s 814ms/step - loss: 0.1447 - dice_coef: 0.8553 - acc: 0.9964 - recall: 0.7060 - precision: 0.9646 - val_loss: 0.1824 - val_dice_coef: 0.8176 - val_acc: 0.9964 - val_recall: 0.7113 - val_precision: 0.9590 - lr: 2.0000e-06\n","Epoch 10/31\n","520/520 [==============================] - 412s 792ms/step - loss: 0.1394 - dice_coef: 0.8606 - acc: 0.9964 - recall: 0.7053 - precision: 0.9660 - val_loss: 0.1780 - val_dice_coef: 0.8220 - val_acc: 0.9964 - val_recall: 0.7195 - val_precision: 0.9592 - lr: 2.0000e-06\n","Epoch 11/31\n","520/520 [==============================] - 412s 792ms/step - loss: 0.1423 - dice_coef: 0.8577 - acc: 0.9964 - recall: 0.7037 - precision: 0.9662 - val_loss: 0.1813 - val_dice_coef: 0.8187 - val_acc: 0.9964 - val_recall: 0.7122 - val_precision: 0.9600 - lr: 2.0000e-06\n","Epoch 12/31\n","520/520 [==============================] - 424s 816ms/step - loss: 0.1461 - dice_coef: 0.8539 - acc: 0.9964 - recall: 0.7065 - precision: 0.9672 - val_loss: 0.1834 - val_dice_coef: 0.8166 - val_acc: 0.9964 - val_recall: 0.7086 - val_precision: 0.9616 - lr: 2.0000e-06\n","Epoch 13/31\n","520/520 [==============================] - 423s 813ms/step - loss: 0.1493 - dice_coef: 0.8507 - acc: 0.9964 - recall: 0.7052 - precision: 0.9669 - val_loss: 0.1797 - val_dice_coef: 0.8203 - val_acc: 0.9964 - val_recall: 0.7117 - val_precision: 0.9627 - lr: 2.0000e-06\n","Epoch 14/31\n","520/520 [==============================] - 425s 818ms/step - loss: 0.1384 - dice_coef: 0.8616 - acc: 0.9964 - recall: 0.7102 - precision: 0.9671 - val_loss: 0.1753 - val_dice_coef: 0.8247 - val_acc: 0.9964 - val_recall: 0.7205 - val_precision: 0.9605 - lr: 2.0000e-06\n","Epoch 15/31\n","520/520 [==============================] - 426s 820ms/step - loss: 0.1435 - dice_coef: 0.8565 - acc: 0.9964 - recall: 0.7109 - precision: 0.9672 - val_loss: 0.1791 - val_dice_coef: 0.8209 - val_acc: 0.9964 - val_recall: 0.7147 - val_precision: 0.9589 - lr: 2.0000e-06\n","Epoch 16/31\n","520/520 [==============================] - 415s 798ms/step - loss: 0.1425 - dice_coef: 0.8575 - acc: 0.9964 - recall: 0.7092 - precision: 0.9683 - val_loss: 0.1727 - val_dice_coef: 0.8273 - val_acc: 0.9964 - val_recall: 0.7222 - val_precision: 0.9612 - lr: 2.0000e-06\n","Epoch 17/31\n","520/520 [==============================] - 426s 820ms/step - loss: 0.1355 - dice_coef: 0.8645 - acc: 0.9964 - recall: 0.7161 - precision: 0.9676 - val_loss: 0.1798 - val_dice_coef: 0.8202 - val_acc: 0.9964 - val_recall: 0.7083 - val_precision: 0.9642 - lr: 2.0000e-06\n","Epoch 18/31\n","520/520 [==============================] - 427s 821ms/step - loss: 0.1413 - dice_coef: 0.8587 - acc: 0.9964 - recall: 0.7140 - precision: 0.9681 - val_loss: 0.1715 - val_dice_coef: 0.8285 - val_acc: 0.9964 - val_recall: 0.7303 - val_precision: 0.9587 - lr: 2.0000e-06\n","Epoch 19/31\n","520/520 [==============================] - 415s 798ms/step - loss: 0.1292 - dice_coef: 0.8708 - acc: 0.9965 - recall: 0.7145 - precision: 0.9685 - val_loss: 0.1713 - val_dice_coef: 0.8287 - val_acc: 0.9964 - val_recall: 0.7203 - val_precision: 0.9619 - lr: 2.0000e-06\n","Epoch 20/31\n","520/520 [==============================] - 414s 797ms/step - loss: 0.1335 - dice_coef: 0.8665 - acc: 0.9965 - recall: 0.7138 - precision: 0.9698 - val_loss: 0.1719 - val_dice_coef: 0.8281 - val_acc: 0.9964 - val_recall: 0.7160 - val_precision: 0.9625 - lr: 2.0000e-06\n","Epoch 21/31\n","520/520 [==============================] - 427s 821ms/step - loss: 0.1363 - dice_coef: 0.8637 - acc: 0.9965 - recall: 0.7204 - precision: 0.9679 - val_loss: 0.1653 - val_dice_coef: 0.8347 - val_acc: 0.9964 - val_recall: 0.7278 - val_precision: 0.9611 - lr: 2.0000e-06\n","Epoch 22/31\n","520/520 [==============================] - 426s 820ms/step - loss: 0.1276 - dice_coef: 0.8724 - acc: 0.9965 - recall: 0.7170 - precision: 0.9698 - val_loss: 0.1662 - val_dice_coef: 0.8338 - val_acc: 0.9964 - val_recall: 0.7211 - val_precision: 0.9615 - lr: 2.0000e-06\n","Epoch 23/31\n","520/520 [==============================] - 427s 822ms/step - loss: 0.1338 - dice_coef: 0.8662 - acc: 0.9965 - recall: 0.7200 - precision: 0.9683 - val_loss: 0.1645 - val_dice_coef: 0.8355 - val_acc: 0.9964 - val_recall: 0.7272 - val_precision: 0.9607 - lr: 2.0000e-06\n","Epoch 24/31\n","520/520 [==============================] - 414s 796ms/step - loss: 0.1228 - dice_coef: 0.8772 - acc: 0.9965 - recall: 0.7166 - precision: 0.9701 - val_loss: 0.1666 - val_dice_coef: 0.8334 - val_acc: 0.9964 - val_recall: 0.7240 - val_precision: 0.9617 - lr: 2.0000e-06\n","Epoch 25/31\n","520/520 [==============================] - 426s 819ms/step - loss: 0.1318 - dice_coef: 0.8682 - acc: 0.9965 - recall: 0.7234 - precision: 0.9703 - val_loss: 0.1657 - val_dice_coef: 0.8343 - val_acc: 0.9964 - val_recall: 0.7360 - val_precision: 0.9589 - lr: 2.0000e-06\n","Epoch 26/31\n","520/520 [==============================] - 427s 820ms/step - loss: 0.1339 - dice_coef: 0.8661 - acc: 0.9965 - recall: 0.7239 - precision: 0.9693 - val_loss: 0.1649 - val_dice_coef: 0.8351 - val_acc: 0.9964 - val_recall: 0.7224 - val_precision: 0.9627 - lr: 2.0000e-06\n","Epoch 27/31\n","520/520 [==============================] - 414s 796ms/step - loss: 0.1262 - dice_coef: 0.8738 - acc: 0.9965 - recall: 0.7202 - precision: 0.9719 - val_loss: 0.1650 - val_dice_coef: 0.8350 - val_acc: 0.9964 - val_recall: 0.7285 - val_precision: 0.9601 - lr: 2.0000e-06\n","Epoch 28/31\n","520/520 [==============================] - 415s 797ms/step - loss: 0.1297 - dice_coef: 0.8703 - acc: 0.9965 - recall: 0.7175 - precision: 0.9718 - val_loss: 0.1610 - val_dice_coef: 0.8390 - val_acc: 0.9965 - val_recall: 0.7301 - val_precision: 0.9625 - lr: 2.0000e-06\n","Epoch 29/31\n","520/520 [==============================] - 414s 796ms/step - loss: 0.1221 - dice_coef: 0.8779 - acc: 0.9965 - recall: 0.7244 - precision: 0.9707 - val_loss: 0.1631 - val_dice_coef: 0.8369 - val_acc: 0.9965 - val_recall: 0.7188 - val_precision: 0.9659 - lr: 2.0000e-06\n","Epoch 30/31\n","520/520 [==============================] - 414s 797ms/step - loss: 0.1120 - dice_coef: 0.8880 - acc: 0.9965 - recall: 0.7224 - precision: 0.9719 - val_loss: 0.1580 - val_dice_coef: 0.8420 - val_acc: 0.9965 - val_recall: 0.7351 - val_precision: 0.9601 - lr: 2.0000e-06\n","Epoch 31/31\n","418/520 [=======================>......] - ETA: 1:15 - loss: 0.1208 - dice_coef: 0.8792 - acc: 0.9965 - recall: 0.7292 - precision: 0.9712"]}],"source":["history2 = model.fit(\n","      X_train, y_train,\n","      batch_size=8,\n","      epochs=31,\n","      verbose=1,\n","      callbacks=callbacks,\n","      validation_data=(X_valid,y_valid))"]},{"cell_type":"markdown","metadata":{"id":"FZwCRz4R-7yY"},"source":["## Next steps..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjUNNbMx-9P4"},"outputs":[],"source":["# It is good, fortunately we got same val_dice_coef as prev ~ 0.84\n","# So it seems now I need to do same preprocessing for all images(or only the 20?) between lacunar and mca.\n","# Make  a dataset (.npy)\n","# extract features from this dataset (csv)\n","# evaluate models perfomance ->\n","#"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["v8rt_QUUthFp","9nUkyINb3zCR","ltHhwU2sY0TD","ppzbluM7fFF7","uxHOyn9MfWnk"],"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
